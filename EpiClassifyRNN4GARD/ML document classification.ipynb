{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to preprocess the dataset and train a recurrent neural network to classify epidemiology studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# load scispaCy models\n",
    "nlpSci = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "nlpSci2 = spacy.load('en_ner_bionlp13cg_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in curator evaluation set (to exclude from the positive and negative sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curator_labeled = pd.read_excel('curator_labeled_dataset.xlsx')\n",
    "curator_pmids = list(curator_labeled['PMID'])\n",
    "for i in range(len(curator_pmids)):\n",
    "    curator_pmids[i] = str(curator_pmids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set preprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "max_length = 300\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "in curator\n",
      "26375 26375 26375\n",
      "26375\n"
     ]
    }
   ],
   "source": [
    "abstracts = []\n",
    "labels = []\n",
    "pmids = []\n",
    "\n",
    "# Read in negative dataset\n",
    "\n",
    "with open(\"negative_dataset.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        abstract = row[1]\n",
    "        # Remove stopwords\n",
    "        for word in STOPWORDS:\n",
    "            token = ' ' + word + ' '\n",
    "            abstract = abstract.replace(token, ' ')\n",
    "            abstract = abstract.replace(' ', ' ')\n",
    "        # Only keep the article if the abstract has more than 5 characters\n",
    "        if len(abstract)>5:\n",
    "            abstracts.append(abstract)\n",
    "            labels.append(0)\n",
    "            pmids.append(row[0])\n",
    "\n",
    "# Read in positive dataset\n",
    "            \n",
    "with open(\"orphanet_epi_mesh.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        abstract = row[1]\n",
    "        # Remove stopwords\n",
    "        for word in STOPWORDS:\n",
    "            token = ' ' + word + ' '\n",
    "            abstract = abstract.replace(token, ' ')\n",
    "            abstract = abstract.replace(' ', ' ')\n",
    "        # Only keep the article if the abstract has more than 5 chars, and it's not one of the curator articles\n",
    "        if len(abstract)>5 and row[0] not in curator_pmids:\n",
    "            abstracts.append(abstract)\n",
    "            labels.append(1)\n",
    "            pmids.append(row[0])\n",
    "\n",
    "print(len(labels), len(abstracts), len(pmids))\n",
    "combined = list(zip(labels, abstracts, pmids))\n",
    "random.shuffle(combined)\n",
    "labels, abstracts, pmids = zip(*combined)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary mapping pmids to indices in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_to_indices = {}\n",
    "for i in range(len(pmids)):\n",
    "    pmid = pmids[i]\n",
    "    pmid_to_indices[pmid] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_abs = int(len(labels) * training_portion) # determine size of training set\n",
    "train_pmids = pmids[0 : train_num_abs]\n",
    "validation_pmids = pmids[train_num_abs:]\n",
    "\n",
    "train_abstracts = []\n",
    "train_labels = []\n",
    "validation_abstracts = []\n",
    "validation_labels = []\n",
    "\n",
    "for pmid in train_pmids:\n",
    "    i = pmid_to_indices[pmid]\n",
    "    train_abstracts.append(abstracts[i])\n",
    "    train_labels.append(labels[i])\n",
    "        \n",
    "for pmid in validation_pmids:\n",
    "    i = pmid_to_indices[pmid]\n",
    "    validation_abstracts.append(abstracts[i])\n",
    "    validation_labels.append(labels[i])\n",
    "        \n",
    "combined = list(zip(train_abstracts, train_labels, train_pmids))\n",
    "random.shuffle(combined)\n",
    "train_abstracts, train_labels, train_pmids = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21100\n",
      "5275\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine positive/negative composition in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119 19981\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for l in train_labels:\n",
    "    if l==1:\n",
    "        pos+=1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(pos,neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the text of the abstract by replacing all named entities with their entity label\n",
    "# Eg: 3 patients were seen in a clinic in England --> CARDINAL patients were seen in a clinic in GPE\n",
    "def standardizeAbstract(abstract):\n",
    "    doc = nlp(abstract)\n",
    "    newAbstract = abstract\n",
    "    # interate through the entities in the abstract\n",
    "    for e in reversed(doc.ents):\n",
    "        # replace entities with their label\n",
    "        if e.label_ in {'PERCENT','CARDINAL','GPE','LOC','DATE','TIME','QUANTITY','ORDINAL'}:\n",
    "            start = e.start_char\n",
    "            end = start + len(e.text)\n",
    "            newAbstract = newAbstract[:start] + e.label_ + newAbstract[end:]\n",
    "    return newAbstract\n",
    "\n",
    "# Same process but include scientific entities from scispaCy models\n",
    "def standardizeSciTerms(abstract):\n",
    "    doc = nlpSci(abstract)\n",
    "    newAbstract = abstract\n",
    "    for e in reversed(doc.ents):\n",
    "        start = e.start_char\n",
    "        end = start + len(e.text)\n",
    "        newAbstract = newAbstract[:start] + e.label_ + newAbstract[end:]\n",
    "        \n",
    "    doc = nlpSci2(newAbstract)\n",
    "    for e in reversed(doc.ents):\n",
    "        start = e.start_char\n",
    "        end = start + len(e.text)\n",
    "        newAbstract = newAbstract[:start] + e.label_ + newAbstract[end:]\n",
    "    return newAbstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstracts_standard = [standardizeAbstract(standardizeSciTerms(abstract)) for abstract in train_abstracts]\n",
    "val_abstracts_standard = [standardizeAbstract(standardizeSciTerms(abstract)) for abstract in validation_abstracts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a tokenizer on the data. Uncommon words are replaced with an OOV (out of vocabulary) token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'disease': 2,\n",
       " 'gene': 3,\n",
       " 'cardinal': 4,\n",
       " 'organism': 5,\n",
       " 'or': 6,\n",
       " 'product': 7,\n",
       " 'chemical': 8,\n",
       " 'tissue': 9,\n",
       " 'the': 10}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_abstracts_standard)\n",
    "word_index = tokenizer.word_index\n",
    "dict(list(word_index.items())[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tokenizer to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tokenizer, convert the texts to matrices, and pad them to a constant length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_abstracts_standard)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5275\n"
     ]
    }
   ],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(val_abstracts_standard)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(len(val_abstracts_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_seq = np.array(train_labels)\n",
    "validation_label_seq = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and reload the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_padded.npy', train_padded)\n",
    "np.save('validation_padded.npy', validation_padded)\n",
    "np.save('train_abstracts.npy', train_abstracts)\n",
    "np.save('validation_abstracts.npy', validation_abstracts)\n",
    "np.save('training_label_seq.npy', training_label_seq)\n",
    "np.save('validation_label_seq.npy', validation_label_seq)\n",
    "np.save('validation_pmids.npy', validation_pmids)\n",
    "np.save('train_pmids.npy', train_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = np.load('train_padded.npy')\n",
    "validation_padded = np.load('validation_padded.npy')\n",
    "train_abstracts = np.load('train_abstracts.npy')\n",
    "validation_abstracts = np.load('validation_abstracts.npy')\n",
    "training_label_seq = np.load('training_label_seq.npy')\n",
    "validation_label_seq = np.load('validation_label_seq.npy')\n",
    "validation_pmids = np.load('validation_pmids.npy')\n",
    "train_pmids = np.load('train_pmids.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print an example preprocessed abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c36bee84e590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreverse_word_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_abstract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_word_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'?'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_abstract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5877\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_index' is not defined"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_abstract(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "print(decode_abstract(train_padded[5877]))\n",
    "print('---')\n",
    "print(train_abstracts[5877])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model. It consists of: an embedding layer, 2 LSTM layers, one dense layer with ReLU activation, and one dense layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 431,554\n",
      "Trainable params: 431,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model. Early stopping halts training if there is an increase in validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "660/660 - 374s - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.0563 - val_accuracy: 0.9881\n",
      "Epoch 2/10\n",
      "660/660 - 369s - loss: 0.0542 - accuracy: 0.9858 - val_loss: 0.0457 - val_accuracy: 0.9898\n",
      "Epoch 3/10\n",
      "660/660 - 433s - loss: 0.0341 - accuracy: 0.9911 - val_loss: 0.1121 - val_accuracy: 0.9750\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam'\n",
    "              , metrics=['accuracy'])\n",
    "num_epochs = 10\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and reload the model architecture and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jennifernj/.local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model_orphanet_final/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model_orphanet_final') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('saved_model/my_model_orphanet_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine predictions on the validation set and calculate precision, recall, F1 score, and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8459980286087543\n",
      "0.9373757336743485\n",
      "0.8855156874583201\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = loaded_model.predict(validation_padded)\n",
    "y_pred = np.argmax(y_pred1, axis=1)\n",
    "\n",
    "print(precision_score(validation_label_seq, y_pred , average=\"macro\"))\n",
    "print(recall_score(validation_label_seq, y_pred , average=\"macro\"))\n",
    "print(f1_score(validation_label_seq, y_pred , average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9373757"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tf.keras.metrics.AUC()\n",
    "_ = m.update_state(validation_label_seq, y_pred)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_to_indices_val = {}\n",
    "for i in range(len(validation_pmids)):\n",
    "    pmid = validation_pmids[i]\n",
    "    pmid_to_indices_val[pmid] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction: 1 [0.33761504 0.6623849 ]\n",
      "label: 0\n",
      "pmid: 32471399\n",
      "BACKGROUND:Ramadan month within Islamic lunar calendar Muslims required fast (abstain food drink) daytime (from sunrise sunset) entire month. Due established connection fasting dehydration acute sialadenitis, aim study determine higher frequency sialadenitis among Muslim population Ramadan months year. METHODS:We conducted retrospective study using medical records 120 Muslim patients admitted emergency room (ER) diagnosed acute sialadenitis 5-year period Baruch Padeh Medical Center, Poriya, St. Vincent de Paul (French) Hospital, Nazareth, located Israel. The study group Muslim patients, aforementioned diagnosis, admitted Ramadan, control group included patients diagnosed sialadenitis rest year. We analyzed overall admission frequency well descriptive diagnostic data, including age, sex, gland involved several blood test results. RESULTS:During month Ramadan, admission Muslims diagnosis acute sialadenitis double months year - difference found statistically significant (p = 0.001). Additionally, found Ramadan sialadenitis patients significantly higher leukocyte numbers admission (p = 0.0085) and, importantly, significantly higher level dehydration (blood urea nitrogen (BUN)/creatinine ratio) non-Ramadan sialadenitis patients (p = 0.0001). CONCLUSION:There evidence fasting Ramadan may increase risk development acute sialadenitis. Our results suggest may result dehydration.\n",
      "\n",
      "prediction: 1 [0.229802   0.77019805]\n",
      "label: 0\n",
      "pmid: 15596620\n",
      "BACKGROUND: X-linked dystonia-parkinsonism (XDP) \"lubag\" X-linked recessive disorder afflicts Filipino men, rarely, women. Genetic confirmation performed haplotyping detection disease-specific changes DYT3 gene. OBJECTIVE: To describe phenotypes molecular data 8 symptomatic female patients XDP 5 kindreds. METHODS: Case series. RESULTS: The average age onset symptoms 52 years (range, 26-75 years). Six 8 patients parkinsonism, whereas 1 dystonia. The initial symptom focal tremor parkinsonism 4, chorea 3, focal dystonia (cervical) 1. Seven 8 patients slow progression symptoms required treatment. The patient disabling parkinsonism responsive carbidopa/levodopa. Seven heterozygous XDP haplotype, whereas 1 homozygous. CONCLUSIONS: The phenotypes female patients XDP may include parkinsonism, dystonia, myoclonus, tremor, chorea. The dystonia, present, mild usually nonprogressive. Similar men XDP, parkinsonism frequent symptom women. In contrast men, affected women benign phenotype, older age onset, milder course. Extreme X-inactivation mosaic may cause symptoms women XDP, homozygously affected woman also observed.\n",
      "\n",
      "prediction: 1 [0.00502657 0.9949734 ]\n",
      "label: 0\n",
      "pmid: 30401706\n",
      "The sideroblastic anemias (SAs) group inherited acquired bone marrow disorders defined pathological iron accumulation mitochondria erythroid precursors. Like hematological diseases, molecular genetic basis SAs ridden wave technology advancement. Within last 30 years, advent positional cloning, human genome project, solid-state genotyping technologies, next-generation sequencing evolved point two-thirds congenital SA cases, even greater proportion cases acquired clonal disease, attributed mutations specific gene genes. This review focuses analysis genetics diseases understanding defects may contribute design implementation rational therapies.\n",
      "\n",
      "prediction: 1 [0.00313944 0.9968606 ]\n",
      "label: 0\n",
      "pmid: 29089398\n",
      "OBJECTIVE:To establish international diagnostic criteria Perry syndrome, disorder characterised clinical signs parkinsonism, depression/apathy, weight loss, respiratory symptoms, mutations DCTN1 gene TAR DNA-binding protein 43 (TDP-43) pathology. METHODS:Data published literature newly identified patients gathered analysed International Symposium Perry syndrome Tokyo identify diagnostic criteria Perry syndrome. RESULTS:Eighty-seven patients Perry syndrome carrying DCTN1 mutations 20 families included study, common signs disorder identified, including parkinsonism (95.2% patients), depression/apathy (71.4%), respiratory symptoms (66.7%) weight loss (49.2%). CONCLUSIONS:Based findings, propose following definitive diagnostic criteria Perry syndrome: presence four cardinal signs Perry syndrome, accompanied mutation DCTN1; family history disease, parkinsonism mutation DCTN1; presence four cardinal signs pathological findings include nigral neuronal loss TDP-43 pathology. As patients Perry syndrome present uniform clinical, genetic pathological features, propose disorder termed 'Perry disease.'\n",
      "\n",
      "prediction: 1 [0.00428048 0.9957195 ]\n",
      "label: 0\n",
      "pmid: 28472977\n",
      "SHORT syndrome rare genetic congenital defects condition. The frequency disease still remains unknown.We report two-year-four-month old female SHORT syndrome present growth retardation dysmorphic features (triangular-shaped face, prominent forehead, ocular depression, lipodystrophy lumbar region around elbows), consistent phenotype described syndrome. The molecular analysis showed presence heterozygous variant c.1956dupT (p.Lys653*) exon 15 PIK3R1.The frequency disease still remains unknown; solely several dozen cases described worldwide.\n",
      "\n",
      "prediction: 1 [0.00647485 0.99352515]\n",
      "label: 0\n",
      "pmid: 30358897\n",
      "Pyruvate kinase deficiency (PKD) common enzyme defect glycolysis important cause hereditary, nonspherocytic hemolytic anemia. The disease worldwide geographical distribution verified data regarding frequency. Difficulties diagnostic workflow interpretation PK enzyme assay likely play role. By creation global PKD International Working Group 2016, involving 24 experts 20 Centers Expertise studied current gaps diagnosis PKD order establish diagnostic guidelines. By means detailed survey subsequent discussions, multiple aspects diagnosis PKD evaluated discussed members Expert Centers Europe, USA, Asia directly involved diagnosis. Broad consensus reached among Centers many clinical technical aspects diagnosis PKD. The results study presented recommendations diagnosis PKD used prepare diagnostic algorithm. This information might helpful Centers deliver timely appropriate diagnosis increase awareness PKD.\n",
      "\n",
      "prediction: 1 [0.00364097 0.99635905]\n",
      "label: 0\n",
      "pmid: 29037509\n",
      "The eosinophilia-myalgia syndrome (EMS) outbreak 1989 occurred USA elsewhere caused ingestion l-Tryptophan (L-Trp) solely manufactured Japanese company Showa Denko K.K. (SD). Six compounds present SD L-Trp reported case-associated contaminants. However, \"one\" compounds, Peak AAA remained structurally uncharacterized, despite fact described \"the statistically significant (p=0.0014) contaminant\". Here, employ on-line microcapillary-high performance liquid chromatography-electrospray ionization mass spectrometry (LC-MS), tandem mass spectrometry (MS/MS) determine Peak AAA fact two structurally related isomers. Peak AAA1 Peak AAA2 differed LC retention times, determined accurate mass-LC-MS protonated molecular ion (MH+) mass 343.239Da (Da), corresponding molecular formula C21H30N2O2, possessing eight degrees unsaturation (DoU) non-protonated molecule. By comparing LC-MS LC-MS-MS retention times spectra authentic synthetic standards, Peak AAA1 identified intermolecular condensation product L-Trp anteiso 7-methylnonanoic acid, afford (S)-2-amino-3-(2-((S,E)-7-methylnon-1-en-1-yl)-1H-indol-3-yl)propanoic acid. Peak AAA2 determined condensation product L-Trp decanoic acid, produced (S)-2-amino-3-(2-((E)-dec-1-en-1-yl)-1H-indol-3-yl)propanoic acid.\n",
      "\n",
      "prediction: 1 [0.32376203 0.676238  ]\n",
      "label: 0\n",
      "pmid: 32647177\n",
      "In study, long-term patient survival plaque brachytherapy uveal melanoma examined. All patients treated 1980 1999 single institution included (n = 677). 533 (79%) deceased end follow-up. The median follow-up 144 survivors 25.4 years (SD 5.2). Uveal melanoma-related mortality 18% 5 years, 28% 10 years, 32% 15 years, 35% 20 years, 36% 25 40 years. 172 209 (82%) uveal melanoma-related deaths occurred within first decade brachytherapy. Relative survival rates 74% 5 years, 64% 10 years, 62% 20 years, 83% 30 years ≥100% 32 to 40 years. Tumor diameter local recurrence independent predictors uveal melanoma-related mortality multivariate Cox proportional hazards analysis. In conclusion, uveal melanoma high mortality rate uveal melanoma-related deaths occur first decade treatment. Long-term survivors may survival advantage individuals sex age general population.\n",
      "\n",
      "prediction: 1 [0.00480457 0.99519545]\n",
      "label: 0\n",
      "pmid: 32477803\n",
      "Among congenital heart disease (CHD) population, intra-atrial reentrant tachycardia (IART) common sequela resulting anatomical anomalies surgical scars significantly increases morbidity mortality. Atrial antitachycardia pacing (ATP) delivered atrial antitachycardia devices (ATDs) used treat IART CHD population. However, remains limited data safety efficacy ATP, well comparisons effects amongst different CHD subtypes. The purpose current study describe clinical history ATP efficacy three patients unique forms complex CHD. During study, single-center review three patients ATDs performed. One patient following CHD anomalies selected inclusion: systemic left ventricle, systemic right ventricle, single ventricle. Data collected included ATP success rates, medications use, direct current (DC) cardioversions, complications related ATDs. Study findings revealed patient systemic left ventricle ATD implanted approximately 9.5 years, 695 956 (73%) episodes successfully converted. Unsuccessfully treated episodes generally asymptomatic self-terminating patient. The patient systemic right ventricle ATD implanted approximately 16 years, 333 348 (96%) episodes successfully converted. The patient single ventricle ATD implanted approximately 12.5 years, 404 416 (97%) episodes successfully converted. The patients biventricular physiology able forgo DC cardioversion receiving ATDs. However, due medical noncompliance well multiple episodes IART, presented 1:1 conduction low rates, single-ventricle patient still required DC cardioversions post-ATD implantation. In conclusion, study's findings demonstrate that, ATP effective wide variety CHDs, experiences vary based individual arrhythmia substrates, cardiac anatomy, medical compliance. Additionally, challenges remain IART detection patients especially complex CHD anatomies.\n",
      "\n",
      "prediction: 1 [0.07356742 0.9264326 ]\n",
      "label: 0\n",
      "pmid: 32547795\n",
      "Hereditary hyperferritinemia cataracts syndrome (HHCS) without iron overload syndrome first identified less 3 decades ago. While investigators dissected gene several responsible mutations reside, remains relatively unknown genetic disorder clinicians. The result often expensive, invasive evaluation iron overload, followed well-intended prescription series phlebotomies delivers morbidity instead benefit. We present father elevated ferritin heterozygosity H63D HFE mutation whose clinical course followed path. His treatment rendered symptomatic iron deficiency reduction ferritin. On re-evaluation, review past medical history clarified cataract surgery noted record occurred young age. Furthermore, one daughters required cataract surgery teenager. With information, strongly suspected HHCS. His phlebotomies discontinued, within weeks, iatrogenic iron deficiency resolved health returned normal.\n",
      "\n",
      "prediction: 1 [0.09666397 0.90333605]\n",
      "label: 0\n",
      "pmid: 32482395\n",
      "OBJECTIVE:To determine whether population level outcomes pediatric acute promyelocytic leukemia improved time. STUDY DESIGN:We conducted retrospective analysis Surveillance Epidemiology End Results database patients acute promyelocytic leukemia, 20 years age, diagnosed 1976 2016 actively followed. Patients stratified based period diagnosis (1976-1989, 1990-1999, 2000-2009, 2010-2016) assess temporal trends overall survival early mortality. RESULTS:A total 553 patients median age 15 years (range, 0-20 years) included. The 5-year overall survival increased significantly time (by 22.6% 1976 1989; 59.2% 1990 1999; 77.7% 2000 2009; 88.9% 2010 2016; P < .001). Early mortality showed improvement time the most recent cohort (by 14% 1976 1989; 13.5% from1990 1999; 13.3% 2000 2009; 7.2% 2010 2016) adjusting demographic characteristics logistic regression model. On multivariate analysis overall survival, diagnosis earlier time periods associated higher mortality compared 2010-2016 period. Age, sex, race/ethnicity significant predictors overall survival. CONCLUSIONS:Outcomes pediatric acute promyelocytic leukemia continued improve time population level.\n",
      "\n",
      "prediction: 1 [0.00679789 0.99320215]\n",
      "label: 0\n",
      "pmid: 32460293\n",
      "OBJECTIVES:In study describe several cases ocular dirofilariasis Bulgaria. MATERIALS AND METHODS:In period 2010-2019, studied 7 patients subconjunctival periorbital form Dirofilaria repens infection. Morphological, serological paraclinical diagnostic methods used. RESULTS:The patients aged 23 72, 6 females 1 male. In 3 patients, subcutaneous nodules detected area upper eyelid, one patient location suborbital. In 3 patients, subconjunctival location found. All patients cured definitively removal larva, without etiologic treatment. CONCLUSION:The reliable easily accessible diagnostic method morphological analysis microscopy histological preparations parasite. In dirofilariasis, ocular location one common cases humans, deserves special attention clinicians.\n",
      "\n",
      "prediction: 1 [0.00519359 0.99480647]\n",
      "label: 0\n",
      "pmid: 32644748\n",
      "In 1937, Joe Vincent Meigs John W Cass reported series 7 cases ovarian fibroma associated ascites hydrothorax. It later termed Meigs syndrome Rhodes Terrell. Even though association benign ovarian tumors pleural effusion reported before, Meigs Cass reported resolution ascites pleural effusion removal tumor. Eventually, several authors reported similar cases, Meigs syndrome became distinct entity. Meigs eventually redefined syndrome 1954. The following criteria met diagnosis Meigs syndrome – a) Presence benign tumor ovary – Fibroma, thecoma, granulosa cell tumor Brenner tumor b) ascites c) pleural effusion d) resolution ascites pleural effusion removal tumor. This syndrome sometimes called Demons-Meigs syndrome another author described similar presentation Meigs.[1][2][3][4] Some patients either ascites pleural effusion benign ovarian tumors classified Atypical/Incomplete Meigs syndrome. Pericardial effusion included definition Meigs syndrome; however, case reports patients unexplained persistent pericardial effusion, resolved resection benign ovarian tumor.[5]\n",
      "\n",
      "prediction: 1 [0.33072793 0.66927207]\n",
      "label: 0\n",
      "pmid: 32308948\n",
      "Purpose:To report 27-year statistical data Central Eye Bank Iran (CEBI) activity. Methods:All CEBI records regarding procured eyes, tissue utilizations, corneal transplants per capita, indications keratoplasty 1991 2017 analyzed. Results:In total, 115,743 whole eyes donated 27-year period. Out 114,169 eyes donated 1994 2017, 95,314 eyes distributed transplantation, 95,057 corneas actually transplanted. The mean annual rate corneal transplants per capita 55.10 -6 ± 27.10 -6 . Although penetrating keratoplasty (PKP, 70%) common technique corneal transplantation study period, exhibited decreasing trend 2006 2017 (P = 0.048). It contrast Descemet stripping automated endothelial keratoplasty (DSAEK) demonstrated increasing trend period (P < 0.001). Keratoconus (KCN, 39.70%) leading indication keratoplasty last three decades followed bullous keratopathy (BK, 18.5%), corneal scar opacities (15.7%), graft failure (GF, 7.5%), increasing trend BK, GF, KCN. A majority scleral tissues (83.7%) utilized orbital implant protection. Conclusion:An increasing trend number procured eyes observed past 27 years Iran. The leading indications corneal transplantation KCN BK. While PKP common keratoplasty technique, DSAEK showed increasing trend last 12 years.\n",
      "\n",
      "prediction: 1 [0.00525808 0.9947419 ]\n",
      "label: 0\n",
      "pmid: 7717420\n",
      "We report 3 members Spanish family partial aphalangia, syndactyly duplication metatarsal IV, microcephaly, dull intelligence, short stature. The MCA pattern observed family appears constitute previously undescribed syndrome.\n",
      "\n",
      "prediction: 1 [0.2708436  0.72915643]\n",
      "label: 0\n",
      "pmid: 28899949\n",
      "The identification multiple endocrine neoplasia type 1 (MEN1) gene 1997 shown germline heterozygous mutations MEN1 gene located chromosome 11q13 predisposes development tumors MEN1 syndrome. Tumor development occurs upon loss remaining normal copy MEN1 gene MEN1-target tissues. Therefore, MEN1 classic tumor suppressor gene context MEN1. This tumor suppressor role protein encoded MEN1 gene, menin, holds true mouse models germline heterozygous Men1 loss, wherein MEN1-associated tumors develop adult mice spontaneous loss remaining non-targeted copy Men1 gene. The availability genetic testing mutations MEN1 gene become essential part diagnosis management MEN1. Genetic testing also helping exclude mutation-negative cases MEN1 families burden lifelong clinical screening. In past 20 years, efforts various groups world-wide directed mutation analysis, molecular genetic studies, mouse models, gene expression studies, epigenetic regulation analysis, biochemical studies anti-tumor effects candidate therapies mouse models. This review focus findings advances studies identify MEN1 germline somatic mutations, genetics MEN1-related states, several protein partners menin, three-dimensional structure menin menin-dependent target genes. The ongoing impact studies disease prediction, management outcomes continue years come.\n",
      "\n",
      "prediction: 1 [0.18815045 0.8118496 ]\n",
      "label: 0\n",
      "pmid: 9382105\n",
      "Hereditary geniospasm unusual movement disorder causing episodes involuntary tremor chin lower lip. Episodes typically start early childhood may precipitated stress, concentration, emotion. Hereditary geniospasm inherited autosomal dominant trait, cause known. We report results genomewide genetic linkage study four-generation British family hereditary geniospasm. Positive two-point LOD scores obtained 15 microsatellite markers peri-centromeric region chromosome 9. A maximum two-point LOD score 5.24 theta = .00 obtained marker D9S1837. Construction haplotypes defined interval 2.1 cM flanking markers D9S1806 D9S175, thus assigning one locus hereditary geniospasm proximal long arm chromosome 9q13-q21. Hereditary geniospasm second British family linked region, indicating genetic heterogeneity. These findings may implications inherited focal movement disorders yet remain unmapped.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if y_pred[i] == 1 and validation_label_seq[i] == 0: # false positives\n",
    "        print('\\nprediction:',y_pred[i], y_pred1[i])\n",
    "        print('label:',validation_label_seq[i])\n",
    "        print('pmid:',validation_pmids[i])\n",
    "        print(validation_abstracts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

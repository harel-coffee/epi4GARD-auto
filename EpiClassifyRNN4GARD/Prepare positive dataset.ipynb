{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the positive dataset.\n",
    "1. Extract PubMed IDs from Orphanet epidemiology sources\n",
    "2. Get MeSH terms for each PubMed ID\n",
    "3. Add all articles with epidemiology, prevalence, or incidence MeSH terms to positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import requests\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlpSci = spacy.load(\"en_ner_bc5cdr_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('en_product9_prev.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine number of sources with PubMed IDs compared to the total number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pmids = 0\n",
    "c = 0\n",
    "for child in root.iter('*'):\n",
    "    if child.tag == 'Source':\n",
    "        c+=1\n",
    "        if 'PMID' in child.text:\n",
    "            pmids = re.findall('\\d{6,8}', child.text)\n",
    "            for pmid in pmids:\n",
    "                num_pmids+=1\n",
    "                c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10845, 26296)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pmids, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble set of pmids for epidemiology studies (prev_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num articles: 0 num epi mesh: 0 any mesh: 0\n",
      "num articles: 100 num epi mesh: 22 any mesh: 48\n",
      "num articles: 200 num epi mesh: 55 any mesh: 90\n",
      "num articles: 300 num epi mesh: 66 any mesh: 106\n",
      "num articles: 400 num epi mesh: 102 any mesh: 160\n",
      "num articles: 500 num epi mesh: 155 any mesh: 219\n",
      "num articles: 600 num epi mesh: 187 any mesh: 261\n",
      "num articles: 700 num epi mesh: 215 any mesh: 303\n",
      "num articles: 800 num epi mesh: 250 any mesh: 355\n",
      "num articles: 900 num epi mesh: 279 any mesh: 413\n",
      "num articles: 1000 num epi mesh: 318 any mesh: 472\n",
      "num articles: 1100 num epi mesh: 342 any mesh: 519\n",
      "num articles: 1200 num epi mesh: 355 any mesh: 560\n",
      "num articles: 1300 num epi mesh: 391 any mesh: 615\n",
      "num articles: 1400 num epi mesh: 414 any mesh: 659\n",
      "num articles: 1500 num epi mesh: 451 any mesh: 715\n",
      "num articles: 1600 num epi mesh: 472 any mesh: 753\n",
      "num articles: 1700 num epi mesh: 520 any mesh: 813\n",
      "num articles: 1800 num epi mesh: 574 any mesh: 874\n",
      "num articles: 1900 num epi mesh: 611 any mesh: 920\n",
      "num articles: 2000 num epi mesh: 646 any mesh: 965\n",
      "num articles: 2100 num epi mesh: 672 any mesh: 1001\n",
      "num articles: 2200 num epi mesh: 716 any mesh: 1060\n",
      "num articles: 2300 num epi mesh: 746 any mesh: 1093\n",
      "num articles: 2400 num epi mesh: 787 any mesh: 1147\n",
      "num articles: 2500 num epi mesh: 826 any mesh: 1205\n",
      "num articles: 2600 num epi mesh: 849 any mesh: 1246\n",
      "num articles: 2700 num epi mesh: 855 any mesh: 1271\n",
      "num articles: 2800 num epi mesh: 857 any mesh: 1289\n",
      "num articles: 2900 num epi mesh: 859 any mesh: 1328\n",
      "num articles: 3000 num epi mesh: 862 any mesh: 1357\n",
      "num articles: 3100 num epi mesh: 864 any mesh: 1387\n",
      "num articles: 3200 num epi mesh: 864 any mesh: 1435\n",
      "num articles: 3300 num epi mesh: 864 any mesh: 1472\n",
      "num articles: 3400 num epi mesh: 866 any mesh: 1500\n",
      "num articles: 3500 num epi mesh: 866 any mesh: 1523\n",
      "num articles: 3600 num epi mesh: 869 any mesh: 1554\n",
      "num articles: 3700 num epi mesh: 876 any mesh: 1588\n",
      "num articles: 3800 num epi mesh: 878 any mesh: 1611\n",
      "num articles: 3900 num epi mesh: 879 any mesh: 1647\n",
      "num articles: 4000 num epi mesh: 881 any mesh: 1677\n",
      "num articles: 4100 num epi mesh: 886 any mesh: 1715\n",
      "num articles: 4200 num epi mesh: 894 any mesh: 1752\n",
      "num articles: 4300 num epi mesh: 896 any mesh: 1775\n",
      "num articles: 4400 num epi mesh: 897 any mesh: 1806\n",
      "num articles: 4500 num epi mesh: 900 any mesh: 1827\n",
      "num articles: 4600 num epi mesh: 908 any mesh: 1855\n",
      "num articles: 4700 num epi mesh: 913 any mesh: 1884\n",
      "num articles: 4800 num epi mesh: 914 any mesh: 1919\n",
      "num articles: 4900 num epi mesh: 918 any mesh: 1947\n",
      "num articles: 5000 num epi mesh: 937 any mesh: 1986\n",
      "num articles: 5100 num epi mesh: 940 any mesh: 2010\n",
      "num articles: 5200 num epi mesh: 951 any mesh: 2048\n",
      "num articles: 5300 num epi mesh: 974 any mesh: 2090\n",
      "num articles: 5400 num epi mesh: 990 any mesh: 2143\n",
      "num articles: 5500 num epi mesh: 1006 any mesh: 2176\n",
      "num articles: 5600 num epi mesh: 1030 any mesh: 2216\n",
      "num articles: 5700 num epi mesh: 1038 any mesh: 2268\n",
      "num articles: 5800 num epi mesh: 1043 any mesh: 2319\n",
      "num articles: 5900 num epi mesh: 1044 any mesh: 2392\n",
      "num articles: 6000 num epi mesh: 1046 any mesh: 2448\n",
      "num articles: 6100 num epi mesh: 1053 any mesh: 2504\n",
      "num articles: 6200 num epi mesh: 1055 any mesh: 2544\n",
      "num articles: 6300 num epi mesh: 1059 any mesh: 2590\n",
      "num articles: 6400 num epi mesh: 1082 any mesh: 2642\n",
      "num articles: 6500 num epi mesh: 1083 any mesh: 2684\n",
      "num articles: 6600 num epi mesh: 1088 any mesh: 2722\n",
      "num articles: 6700 num epi mesh: 1096 any mesh: 2776\n",
      "num articles: 6800 num epi mesh: 1098 any mesh: 2812\n",
      "num articles: 6900 num epi mesh: 1110 any mesh: 2864\n",
      "num articles: 7000 num epi mesh: 1111 any mesh: 2926\n",
      "num articles: 7100 num epi mesh: 1113 any mesh: 2995\n",
      "num articles: 7200 num epi mesh: 1115 any mesh: 3056\n",
      "num articles: 7300 num epi mesh: 1121 any mesh: 3114\n",
      "num articles: 7400 num epi mesh: 1127 any mesh: 3161\n",
      "num articles: 7500 num epi mesh: 1128 any mesh: 3208\n",
      "num articles: 7600 num epi mesh: 1129 any mesh: 3263\n",
      "num articles: 7700 num epi mesh: 1132 any mesh: 3320\n",
      "num articles: 7800 num epi mesh: 1150 any mesh: 3377\n",
      "num articles: 7900 num epi mesh: 1157 any mesh: 3433\n",
      "num articles: 8000 num epi mesh: 1169 any mesh: 3492\n",
      "num articles: 8100 num epi mesh: 1182 any mesh: 3537\n",
      "num articles: 8200 num epi mesh: 1193 any mesh: 3601\n",
      "num articles: 8300 num epi mesh: 1193 any mesh: 3660\n",
      "num articles: 8400 num epi mesh: 1215 any mesh: 3711\n",
      "num articles: 8500 num epi mesh: 1225 any mesh: 3757\n",
      "num articles: 8600 num epi mesh: 1237 any mesh: 3794\n",
      "num articles: 8700 num epi mesh: 1245 any mesh: 3841\n",
      "num articles: 8800 num epi mesh: 1261 any mesh: 3886\n",
      "num articles: 8900 num epi mesh: 1280 any mesh: 3940\n",
      "num articles: 9000 num epi mesh: 1298 any mesh: 3991\n",
      "num articles: 9100 num epi mesh: 1315 any mesh: 4049\n",
      "num articles: 9200 num epi mesh: 1334 any mesh: 4108\n",
      "num articles: 9300 num epi mesh: 1344 any mesh: 4153\n",
      "num articles: 9400 num epi mesh: 1354 any mesh: 4204\n",
      "num articles: 9500 num epi mesh: 1376 any mesh: 4249\n",
      "num articles: 9600 num epi mesh: 1383 any mesh: 4262\n",
      "num articles: 9700 num epi mesh: 1384 any mesh: 4301\n",
      "num articles: 9800 num epi mesh: 1397 any mesh: 4344\n",
      "num articles: 9900 num epi mesh: 1417 any mesh: 4386\n",
      "num articles: 10000 num epi mesh: 1434 any mesh: 4428\n",
      "num articles: 10100 num epi mesh: 1439 any mesh: 4452\n",
      "num articles: 10200 num epi mesh: 1455 any mesh: 4490\n",
      "num articles: 10300 num epi mesh: 1456 any mesh: 4493\n",
      "num articles: 10400 num epi mesh: 1457 any mesh: 4494\n",
      "num articles: 10500 num epi mesh: 1467 any mesh: 4522\n",
      "num articles: 10600 num epi mesh: 1483 any mesh: 4564\n",
      "num articles: 10700 num epi mesh: 1490 any mesh: 4614\n",
      "num articles: 10800 num epi mesh: 1502 any mesh: 4674\n"
     ]
    }
   ],
   "source": [
    "prev_pmids = set()\n",
    "i = 0\n",
    "any_tags = 0 # number of articles with any MeSH tags (not just epidemiology)\n",
    "for child in root.iter('*'):\n",
    "    if child.tag == 'Source' and 'PMID' in child.text:\n",
    "        pmids = re.findall('\\d{6,8}', child.text)\n",
    "        for pmid in pmids:\n",
    "            if i % 100 == 0:\n",
    "                print('num articles:',i, 'num epi mesh:', len(prev_pmids), 'any mesh:',any_tags)\n",
    "            i += 1\n",
    "            if pmid not in prev_pmids:\n",
    "                is_case = False # is case report\n",
    "                url = 'https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=EXT_ID:'+pmid+'&resulttype=core'\n",
    "                r = requests.get(url)\n",
    "                pub_root = ET.fromstring(r.content)\n",
    "                \n",
    "                hasMesh = False # has epidemiology MeSH terms\n",
    "                anyMesh = False # has any MeSH terms\n",
    "    \n",
    "                for child in pub_root.iter('*'):\n",
    "                    if 'mesh' in child.tag:\n",
    "                        anyMesh = True\n",
    "                    if child.tag == 'qualifierName' or child.tag == 'descriptorName':\n",
    "                        if child.text.lower() in {'prevalence','epidemiology','incidence'}:\n",
    "                            hasMesh = True\n",
    "                    # exclude case reports\n",
    "                    if child.tag == 'pubType':\n",
    "                        if child.text == 'Case Reports':\n",
    "                            is_case = True\n",
    "                            break\n",
    "                if anyMesh:\n",
    "                    any_tags += 1\n",
    "                if hasMesh and not is_case:\n",
    "                    prev_pmids.add(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prev_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_results_mesh = pd.DataFrame(columns=['pmid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_results_mesh['pmid'] = list(prev_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_results_mesh.to_csv('orphanet_epi_mesh.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add abstract column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbs(pmid):\n",
    "    url = 'https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=EXT_ID:'+str(pmid)+'&resulttype=core'\n",
    "    r = requests.get(url)\n",
    "    root = ET.fromstring(r.content)\n",
    "    \n",
    "    results = [abstract.text for abstract in root.iter('abstractText')]\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        return results[0]\n",
    "    else:\n",
    "        return ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphanet_epi_mesh= pd.read_csv('orphanet_epi_mesh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "abstracts = []\n",
    "for i,row in orphanet_epi_mesh.iterrows():\n",
    "    if i%50 == 0:\n",
    "        print(i)\n",
    "    abstracts.append(getAbs(row['pmid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orphanet_epi_mesh['abstract'] = abstracts\n",
    "orphanet_epi_mesh['abstract'].replace('', np.nan, inplace=True)\n",
    "orphanet_epi_mesh.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphanet_epi_mesh.to_csv('orphanet_epi_mesh.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option to add articles from searches for rare disease names that have epidemiology MeSH terms. (Resulted in poorer performance from my testing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all rare disease names on GARD\n",
    "with open('records.json') as f:\n",
    "    records = json.load(f)\n",
    "    \n",
    "disorders = set()\n",
    "\n",
    "for entry in records:\n",
    "    disorders.add(entry['GARD_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "50 25\n",
      "100 54\n",
      "150 90\n",
      "200 113\n",
      "250 160\n",
      "300 193\n",
      "350 222\n",
      "400 253\n",
      "450 280\n",
      "500 315\n",
      "550 352\n",
      "600 381\n",
      "650 414\n",
      "700 432\n",
      "750 455\n",
      "800 479\n",
      "850 501\n",
      "900 541\n",
      "950 581\n",
      "1000 600\n",
      "1050 632\n",
      "1100 656\n",
      "1150 689\n",
      "1200 714\n",
      "1250 764\n",
      "1300 804\n",
      "1350 831\n",
      "1400 851\n",
      "1450 876\n",
      "1500 890\n",
      "1550 912\n",
      "1600 937\n",
      "1650 960\n",
      "1700 991\n",
      "1750 1018\n",
      "1800 1045\n",
      "1850 1065\n",
      "1900 1091\n",
      "1950 1142\n",
      "2000 1167\n",
      "2050 1202\n",
      "2100 1229\n",
      "2150 1279\n",
      "2200 1309\n",
      "2250 1328\n",
      "2300 1361\n",
      "2350 1392\n",
      "2400 1419\n",
      "2450 1447\n",
      "2500 1498\n",
      "2550 1535\n",
      "2600 1556\n",
      "2650 1592\n",
      "2700 1628\n",
      "2750 1658\n",
      "2800 1694\n",
      "2850 1721\n",
      "2900 1771\n",
      "2950 1816\n",
      "3000 1846\n",
      "3050 1875\n",
      "3100 1896\n",
      "3150 1926\n",
      "3200 1950\n",
      "3250 1983\n",
      "3300 2012\n",
      "3350 2055\n",
      "3400 2079\n",
      "3450 2103\n",
      "3500 2129\n",
      "3550 2156\n",
      "3600 2185\n",
      "3650 2202\n",
      "3700 2227\n",
      "3750 2255\n",
      "3800 2278\n",
      "3850 2310\n",
      "3900 2340\n",
      "3950 2372\n",
      "4000 2410\n",
      "4050 2437\n",
      "4100 2459\n",
      "4150 2490\n",
      "4200 2523\n",
      "4250 2545\n",
      "4300 2563\n",
      "4350 2596\n",
      "4400 2623\n",
      "4450 2649\n",
      "4500 2682\n",
      "4550 2705\n",
      "4600 2741\n",
      "4650 2773\n",
      "4700 2805\n",
      "4750 2830\n",
      "4800 2856\n",
      "4850 2892\n",
      "4900 2918\n",
      "4950 2939\n",
      "5000 2961\n",
      "5050 2987\n",
      "5100 3015\n",
      "5150 3065\n",
      "5200 3105\n",
      "5250 3129\n",
      "5300 3167\n",
      "5350 3208\n",
      "5400 3243\n",
      "5450 3278\n",
      "5500 3305\n",
      "5550 3349\n",
      "5600 3378\n",
      "5650 3428\n",
      "5700 3469\n",
      "5750 3495\n",
      "5800 3534\n",
      "5850 3559\n",
      "5900 3595\n",
      "5950 3617\n",
      "6000 3662\n",
      "6050 3692\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "keywords = {'prevalence','epidemiology','incidence'}\n",
    "all_disorders_mesh = pd.DataFrame(columns=['pmid', 'abstract'])\n",
    "for dz in disorders:\n",
    "    if j%50 == 0:\n",
    "        print(j, len(pos_results_disorders))\n",
    "    j+=1\n",
    "    \n",
    "    # get results from searching for rare disease name through EBI API\n",
    "    term = ''\n",
    "    dz_words = dz.split()\n",
    "    for word in dz_words:\n",
    "        term += word + '%20'\n",
    "    query = term[:-3]\n",
    "    url = 'https://www.ebi.ac.uk/europepmc/webservices/rest/search?query='+query+'&resulttype=core'\n",
    "    r = requests.get(url)\n",
    "    root = ET.fromstring(r.content)\n",
    "    \n",
    "    pmid_to_abs = {}\n",
    "    \n",
    "    for result in root.iter('result'):\n",
    "        pmids = [pmid.text for pmid in result.iter('id')]\n",
    "        if len(pmids) > 0:\n",
    "            pmid = pmids[0]\n",
    "            if pmid[0].isdigit():\n",
    "                abstracts = [abstract.text for abstract in result.iter('abstractText')]\n",
    "                if len(abstracts) > 0:\n",
    "                    mesh = set(mesh.text.lower() for mesh in result.iter('descriptorName'))\n",
    "                    mesh2 = set(mesh.text.lower() for mesh in result.iter('qualifierName'))\n",
    "                    # add the pmid if its article has epidemiology MeSH terms\n",
    "                    if len(mesh & keywords) != 0 or len(mesh2 & keywords) != 0:\n",
    "                        all_disorders_mesh = all_disorders_mesh.append({'pmid':pmid, 'abstract':abstracts[0]}\n",
    "                                         , ignore_index=True)\n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disorders_mesh.to_csv('all_disorders_mesh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disorders_mesh = pd.read_csv('all_disorders_mesh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([all_disorders_mesh, orphanet_epi_mesh]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('all_mesh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

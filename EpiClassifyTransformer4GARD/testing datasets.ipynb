{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6238fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a0e75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset epi_classify4_gard (/home/wzkariampuzha/.cache/huggingface/datasets/epi_classify4_gard/default/0.0.0/d1a2905805b51e215c521c58c69f678e87ea84d0074a5e20636debc9b862816d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcea33750324f1fb5fec63b176ae2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ncats/EpiClassify4GARD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac0f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['abstract', 'label'],\n",
       "        num_rows: 18433\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['abstract', 'label'],\n",
       "        num_rows: 7901\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['abstract', 'label'],\n",
       "        num_rows: 98\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ncats/EpiClassify4GARD\", delimiter='\\t',split =['train','validation','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files={'train':'epi_classify_train.tsv', \n",
    "                                          'validation':'epi_classify_val.tsv',\n",
    "                                          'test': 'epi_classify_test.tsv'}, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk('epi_classify_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce373199",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = load_from_disk('epi_classify_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a896485",
   "metadata": {},
   "source": [
    "Unused Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650dab1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pyarrow.csv as pac   # PyArrow is installed with `datasets`\n",
    "\n",
    "#dataset = load_dataset('ncats/EpiClassify4GARD')\n",
    "dataset = load_dataset('csv', data_files={'train':'epi_classify_train.csv', \n",
    "                                          'validation':'epi_classify_val.csv',\n",
    "                                          'test': 'epi_classify_test.csv'}, read_options=read_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870c362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_test = load_dataset('csv', data_files={'test': 'epi_classify_test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf15f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c27568",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482084c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test['test']['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_val = load_dataset('csv', data_files={'train':'epi_classify_train.csv', \n",
    "                                                    'validation':'epi_classify_val.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6f456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e875441",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, encoding=\"utf-8\") as f:\n",
    "    data = csv.reader(f, delimiter=\"\\t\")\n",
    "    next(data)\n",
    "    for id_, row in enumerate(data):\n",
    "        yield id_, {\n",
    "            \"text\": row[0],\n",
    "            \"label\": int(row[1]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade3d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50ad9a",
   "metadata": {},
   "source": [
    "# Goal: \n",
    "Utilize \n",
    "Transformers [GLUE Pytorch code](https://github.com/huggingface/transformers/tree/master/examples/pytorch/text-classification) with sst2 task (sentiment analysis) but instead of sentiment classify as epi or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97511f",
   "metadata": {},
   "source": [
    "Open the sst2 dataset and see how it is formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_glue = load_dataset('glue','sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ea2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59687860",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ncats/EpiSet4NER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac1721",
   "metadata": {},
   "source": [
    "Different saving strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c03622",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "for i in range(1,len(train_set)):\n",
    "    training.append({'abstract':train_set[i][0],'label':train_set[i][1],'index':i-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = []\n",
    "for i in range(1,len(val_set)):\n",
    "    validation.append({'abstract':val_set[i][0],'label':val_set[i][1],'index':i-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d31dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format1 = {'train':{'abstract':train_set[i][0],'label':train_set[i][1],'index':i-1 for i in range(1,len(train_set))},'validation':{'abstract':val_set[i][0],'label':val_set[i][1],'index':i-1 for i in range(1,len(val_set))}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035edcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data_format1.json', 'w') as f:\n",
    "    json.dump(data_format1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('json', data_files='data_format1.json', field='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9f69f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd29f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training.jsonl', \"w\") as f:\n",
    "    for i in range(len(training)):\n",
    "        output = str(training[i])+'\\n'\n",
    "        f.write(output)\n",
    "        if i%500==0:\n",
    "            print('abstract num',i,'done')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de026858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('epiclassify.json', 'w') as f:\n",
    "    json.dump({'train':training,'validation':validation}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f726e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('json', data_files='epiclassify.json', field='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd8127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4174af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('json', data_files='training.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46342c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "y = DatasetDict.from_json('epiclassify.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e9ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

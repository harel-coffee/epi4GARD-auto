{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f22c8d6",
   "metadata": {},
   "source": [
    "# Goals: \n",
    "- Find out precision, recall, F1 for each tag class in predictions compared to test set on a token level and entity level.\n",
    "- Can also use this to compare the unmodified test set to the modified test set\n",
    "\n",
    "Must change out comparison set at top and bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf76fb",
   "metadata": {},
   "source": [
    "## Token-Level Evaluation\n",
    "- This ignores differences between B-{tag} and I-{tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e250288",
   "metadata": {},
   "source": [
    "Import the comparison set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ceb9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport csv\\nwith open(\\'./epi_test_setV3.tsv\\',\\'r\\') as f:\\n    reader = csv.reader(f, delimiter=\"\\t\")\\n    pred_tokens = [row[0] for row in reader if len(row)>1]\\n    f.seek(0)\\n    pred_tags = [row[1] for row in reader if len(row)>1]\\nf.close()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the the original unmodified test set\n",
    "# can change out for any of the other two sets below\n",
    "'''\n",
    "import csv\n",
    "with open('./epi_test_setV3.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6010cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the predicted data (final custom dataset)\n",
    "\n",
    "import csv\n",
    "with open('./resultsV3.2/test_predictions.txt','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    \n",
    "    #for row in reader:\n",
    "    #    if len(row)>1:\n",
    "    #        print(row[0],row[1])\n",
    "    #    else:\n",
    "    #        print('')\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6fa19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Load the predicted data (large dataset)\\nimport csv\\nwith open(\\'./resultsV3.2Large/test_predictions.txt\\',\\'r\\') as f:\\n    reader = csv.reader(f, delimiter=\" \")\\n    pred_tokens = [row[0] for row in reader if len(row)>1]\\n    f.seek(0)\\n    pred_tags = [row[1] for row in reader if len(row)>1]\\nf.close()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Load the predicted data (large dataset)\n",
    "import csv\n",
    "with open('./resultsV3.2Large/test_predictions.txt','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fa834b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context O\n",
      "Patients O\n",
      "with O\n",
      "pseudohypoparathyroidism O\n",
      "type O\n",
      "1b O\n",
      "( O\n",
      "PHP1b O\n",
      ") O\n",
      "show O\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(pred_tokens[x],pred_tags[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ace89a",
   "metadata": {},
   "source": [
    "Import ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfedefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the corrected (modified) test set data\n",
    "# DO NOT CHANGE\n",
    "mod_tokens, mod_tags= [],[]\n",
    "with open('epi_test_setV2-corrected.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    mod_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    mod_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5932dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context O\n",
      "Patients O\n",
      "with O\n",
      "pseudohypoparathyroidism O\n",
      "type O\n",
      "1b O\n",
      "( O\n",
      "PHP1b O\n",
      ") O\n",
      "show O\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(mod_tokens[x],mod_tags[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e72dde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13910 13910\n",
      "13910 13910\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_tokens),len(mod_tokens))\n",
    "print(len(pred_tags),len(mod_tags))\n",
    "#Some of the sentences were combined when fixing the test set so there are now different number of sentences and different sizes of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8711157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tag(pred_tag,mod_tag):\n",
    "    \n",
    "    changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem=0,0,0,0,0,0,0,0,0\n",
    "    \n",
    "    if pred_tag != mod_tag:\n",
    "        #This will add everything, including ones that change from I-LOC -> B-LOC, the others won't\n",
    "        changes+=1\n",
    "        \n",
    "        #False positives\n",
    "        if 'LOC' in pred_tag and 'LOC' not in mod_tag:\n",
    "            loc_rem+=1\n",
    "        elif 'DIS' in pred_tag and 'DIS' not in mod_tag:\n",
    "            dz_rem+=1\n",
    "        elif 'STAT' in pred_tag and 'STAT' not in mod_tag:\n",
    "            stat_rem+=1\n",
    "        elif 'EPI' in pred_tag and 'EPI' not in mod_tag:\n",
    "            epi_rem+=1\n",
    "        \n",
    "        #False negatives\n",
    "        if 'LOC' in mod_tag and 'LOC' not in pred_tag:\n",
    "            loc_add+=1\n",
    "        elif 'DIS' in mod_tag and 'DIS' not in pred_tag:\n",
    "            dz_add+=1\n",
    "        elif 'STAT' in mod_tag and 'STAT' not in pred_tag:\n",
    "            stat_add+=1\n",
    "        elif 'EPI' in mod_tag and 'EPI' not in pred_tag:\n",
    "            epi_add+=1\n",
    "        return changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem\n",
    "    else:\n",
    "        return changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68b826",
   "metadata": {},
   "source": [
    "Iterate through all tokens and labels but also accounts for small mismatches (off by one) in the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a268fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch:  296 \n",
      "loc_fn:  39 \n",
      "loc_fp:  6 \n",
      "stat_fn:  125 \n",
      "stat_fp:  83 \n",
      "dz_fn:  0 \n",
      "dz_fp:  0 \n",
      "epi_fn:  9 \n",
      "epi_fp:  11 \n",
      "skipped annotations:  0\n"
     ]
    }
   ],
   "source": [
    "mismatch, loc_fn, loc_fp, stat_fn, stat_fp, dz_fn, dz_fp, epi_fn,epi_fp=0,0,0,0,0,0,0,0,0\n",
    "mod_idx, pred_idx=0,0\n",
    "skipped_annotations=0\n",
    "\n",
    "while pred_idx<len(pred_tokens) and mod_idx<len(mod_tokens):\n",
    "    if mod_tokens[mod_idx] != pred_tokens[pred_idx]:\n",
    "        if mod_tokens[mod_idx+1] == pred_tokens[pred_idx]:\n",
    "            mod_idx+=1\n",
    "            #compare\n",
    "            changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem = compare_tag(\n",
    "                pred_tags[pred_idx],mod_tags[mod_idx])\n",
    "            mismatch+=changes\n",
    "            loc_fn+=loc_add\n",
    "            loc_fp+=loc_rem\n",
    "            stat_fn+=stat_add\n",
    "            stat_fp+=stat_rem\n",
    "            dz_fn+=dz_add\n",
    "            dz_fp+=dz_rem\n",
    "            epi_fn+=epi_add\n",
    "            epi_fp+=epi_rem\n",
    "            \n",
    "            pred_idx+=1\n",
    "            mod_idx+=1\n",
    "        elif mod_tokens[mod_idx] == pred_tokens[pred_idx+1]:\n",
    "            pred_idx+=1\n",
    "            #compare\n",
    "            changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem = compare_tag(\n",
    "                pred_tags[pred_idx],mod_tags[mod_idx])\n",
    "            mismatch+=changes\n",
    "            loc_fn+=loc_add\n",
    "            loc_fp+=loc_rem\n",
    "            stat_fn+=stat_add\n",
    "            stat_fp+=stat_rem\n",
    "            dz_fn+=dz_add\n",
    "            dz_fp+=dz_rem\n",
    "            epi_fn+=epi_add\n",
    "            epi_fp+=epi_rem\n",
    "            \n",
    "            pred_idx+=1\n",
    "            mod_idx+=1\n",
    "        \n",
    "        else:\n",
    "            print('uh oh-->','mod_idx:',mod_idx,', pred_idx:',pred_idx)\n",
    "            print(mod_tokens[mod_idx],pred_tokens[pred_idx])\n",
    "            skipped_annotations+=1\n",
    "            pred_idx+=1\n",
    "            mod_idx+=1\n",
    "            #skip compare\n",
    "    else:\n",
    "        #compare\n",
    "        changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem = compare_tag(\n",
    "            pred_tags[pred_idx],mod_tags[mod_idx])\n",
    "        mismatch+=changes\n",
    "        loc_fn+=loc_add\n",
    "        loc_fp+=loc_rem\n",
    "        stat_fn+=stat_add\n",
    "        stat_fp+=stat_rem\n",
    "        dz_fn+=dz_add\n",
    "        dz_fp+=dz_rem\n",
    "        epi_fn+=epi_add\n",
    "        epi_fp+=epi_rem\n",
    "        \n",
    "        pred_idx+=1\n",
    "        mod_idx+=1\n",
    "            \n",
    "\n",
    "print('mismatch: ',mismatch, \n",
    "      '\\nloc_fn: ',loc_fn, \n",
    "      '\\nloc_fp: ',loc_fp, \n",
    "      '\\nstat_fn: ',stat_fn, \n",
    "      '\\nstat_fp: ',stat_fp, \n",
    "      '\\ndz_fn: ',dz_fn, \n",
    "      '\\ndz_fp: ',dz_fp, \n",
    "      '\\nepi_fn: ',epi_fn, \n",
    "      '\\nepi_fp: ',epi_fp,\n",
    "      '\\nskipped annotations: ',int(skipped_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3a6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of true positives\n",
    "def count_tags(tags):\n",
    "    l,d,s,e = 0,0,0,0\n",
    "    for tag in tags:\n",
    "        if 'LOC' in tag:\n",
    "            l+=1\n",
    "        elif 'DIS' in tag:\n",
    "            d+=1\n",
    "        elif 'STAT' in tag:\n",
    "            s+=1\n",
    "        elif 'EPI' in tag:\n",
    "            e+=1\n",
    "    return l,d,s,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8b9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(tp,fp,fn):\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    F1=(2*precision*recall)/(precision+recall)\n",
    "    return {'precision':precision,'recall':recall,'F1':F1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f649f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-level overall precision 0.8109640831758034\n",
      "token-level overall recall 0.7126245847176079\n",
      "token-level overall F1 0.7586206896551723\n",
      "\n",
      "location classification precision 0.9491525423728814\n",
      "location classification recall 0.7417218543046358\n",
      "location classification F1 0.8327137546468403\n",
      "\n",
      "epidemiology word classification precision 0.9\n",
      "epidemiology word classification recall 0.9166666666666666\n",
      "epidemiology word classification F1 0.908256880733945\n",
      "\n",
      "statistic identification precision 0.7242524916943521\n",
      "statistic identification recall 0.6355685131195336\n",
      "statistic identification F1 0.6770186335403726\n",
      "\n",
      "overall accuracy 0.9787203450754852\n"
     ]
    }
   ],
   "source": [
    "loc_tp, dz_tp, stat_tp, epi_tp = count_tags(mod_tags)\n",
    "#dz_stats = get_stats(dz_tp,dz_fp,dz_fn)\n",
    "loc_stats = get_stats(loc_tp,loc_fp,loc_fn)\n",
    "stat_stats = get_stats(stat_tp,stat_fp,stat_fn)\n",
    "epi_stats = get_stats(epi_tp,epi_fp,epi_fn)\n",
    "overall_stats = get_stats(loc_tp+dz_tp+stat_tp+epi_tp, loc_fp+dz_fp+stat_fp+epi_fp, dz_fn+loc_fn+stat_fn+epi_fn)\n",
    "\n",
    "\n",
    "for k,v in overall_stats.items():\n",
    "    print('token-level overall',k,v)\n",
    "print('')\n",
    "#for k,v in dz_stats.items():\n",
    "#    print('disease classification',k,v)\n",
    "#print('')\n",
    "for k,v in loc_stats.items():\n",
    "    print('location classification',k,v)\n",
    "print('')\n",
    "for k,v in epi_stats.items():\n",
    "    print('epidemiology word classification',k,v)\n",
    "print('')\n",
    "for k,v in stat_stats.items():\n",
    "    print('statistic identification',k,v)\n",
    "print('')\n",
    "print('overall accuracy',1-(mismatch)/(len(mod_tags)-skipped_annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda05dc",
   "metadata": {},
   "source": [
    "## Entity-Level Evaluation (with seqeval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb1780",
   "metadata": {},
   "source": [
    "Must re-input the comparison files because this is list of lists of tags, not just list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c52b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "#Import ground truth, do not change\n",
    "y_true= []\n",
    "with open('epi_test_setV2-corrected.tsv','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentences_tags=[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                y_true.append(sentences_tags.copy())\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2194fd7",
   "metadata": {},
   "source": [
    "Import comparison set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f831cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#load the original data\\ny_pred= []\\nwith open(\\'epi_test_setV3.tsv\\',\\'r\\', encoding=\"utf-8\") as f:\\n    reader = csv.reader(f, delimiter=\"\\t\")\\n    sentences_tags=[]\\n    for row in reader:\\n        if len(row)%2==0:\\n            if len(row)==0:\\n                y_pred.append(sentences_tags.copy())\\n                sentences_tags.clear()\\n            else:\\n                sentences_tags.append(row[1])\\nf.close()\\nprint(len(y_pred))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#load the original data\n",
    "y_pred= []\n",
    "with open('epi_test_setV3.tsv','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentences_tags=[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                y_pred.append(sentences_tags.copy())\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(y_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e70ad95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#load the Custom predicted data\\ny_pred= []\\nwith open(\\'./resultsV3.2/test_predictions.txt\\',\\'r\\', encoding=\"utf-8\") as f:\\n    reader = csv.reader(f, delimiter=\" \")\\n    sentences_tags=[]\\n    for row in reader:\\n        if len(row)%2==0:\\n            if len(row)==0:\\n                y_pred.append(sentences_tags.copy())\\n                sentences_tags.clear()\\n            else:\\n                sentences_tags.append(row[1])\\nf.close()\\nprint(len(y_pred))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#load the Custom predicted data\n",
    "y_pred= []\n",
    "with open('./resultsV3.2/test_predictions.txt','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    sentences_tags=[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                y_pred.append(sentences_tags.copy())\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(y_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43614fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "#load the large predicted data\n",
    "\n",
    "y_pred= []\n",
    "with open('./resultsV3.2Large/test_predictions.txt','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    sentences_tags=[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                y_pred.append(sentences_tags.copy())\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c988c5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "def get_seqevalmetrics(y_true,y_pred):\n",
    "    return {\n",
    "            \"precision\": precision_score(y_true, y_pred),\n",
    "            \"recall\": recall_score(y_true, y_pred),\n",
    "            \"f1\": f1_score(y_true, y_pred),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e74d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL {'precision': 0.5137254901960784, 'recall': 0.6517412935323383, 'f1': 0.5745614035087719}\n"
     ]
    }
   ],
   "source": [
    "print('OVERALL',get_seqevalmetrics(y_true,y_pred))\n",
    "#for k,v in get_seqevalmetrics(y_true,y_pred).items():\n",
    "#    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed00e61",
   "metadata": {},
   "source": [
    "### Get individual entity types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d29e8",
   "metadata": {},
   "source": [
    "This will normalize all other entities except for a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c0a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION {'precision': 0.5645161290322581, 'recall': 0.625, 'f1': 0.5932203389830509}\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "#LOCATION\n",
    "y_true_loc = deepcopy(y_true)\n",
    "y_pred_loc = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'LOC' not in y_pred[i][j]:\n",
    "            y_pred_loc[i][j] = 'O'\n",
    "        if 'LOC' not in y_true[i][j]:\n",
    "            y_true_loc[i][j] = 'O'\n",
    "\n",
    "print('LOCATION',get_seqevalmetrics(y_true_loc,y_pred_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e68f3912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epi Identifier {'precision': 0.8367346938775511, 'recall': 0.9111111111111111, 'f1': 0.8723404255319148}\n"
     ]
    }
   ],
   "source": [
    "#EPI IDENTIFIER\n",
    "y_true_epi = deepcopy(y_true)\n",
    "y_pred_epi = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'EPI' not in y_true[i][j]:\n",
    "            y_true_epi[i][j] = 'O'\n",
    "        if 'EPI' not in y_pred[i][j]:\n",
    "            y_pred_epi[i][j] = 'O'\n",
    "\n",
    "print('Epi Identifier',get_seqevalmetrics(y_true_epi,y_pred_epi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60ec918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPI RATE {'precision': 0.14736842105263157, 'recall': 0.2545454545454545, 'f1': 0.18666666666666665}\n"
     ]
    }
   ],
   "source": [
    "#EPI Rate\n",
    "y_true_stat = deepcopy(y_true)\n",
    "y_pred_stat = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'STAT' not in y_true[i][j]:\n",
    "            y_true_stat[i][j] = 'O'\n",
    "        if 'STAT' not in y_pred[i][j]:\n",
    "            y_pred_stat[i][j] = 'O'\n",
    "\n",
    "print('EPI RATE',get_seqevalmetrics(y_true_stat,y_pred_stat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f22c8d6",
   "metadata": {},
   "source": [
    "# Goals: \n",
    "- Find out precision, recall, F1 for each tag class in predictions compared to test/val set on a token level and entity level.\n",
    "- Cannot use this to compare the unmodified test set to the modified test set because the modified test set is too differen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7086931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#Final Model Test\n",
    "#path_to_true_dataset = r\"./datasets/epi_gold-dz/test.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/o14/test_predictions.txt'\n",
    "\n",
    "#Final Model Evaluation\n",
    "path_to_true_dataset = r\"./datasets/epi_gold-dz/val.tsv\"\n",
    "path_to_pred_dataset = r'./NER/o14/eval_predictions.txt'\n",
    "\n",
    "\n",
    "## Initial Evaluations\n",
    "#BioBERT Large initial evaluation\n",
    "#path_to_true_dataset = r\"./datasets/dmis-lab/biobert-large-cased-v1.1/val.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/output2/eval_predictions.txt'\n",
    "\n",
    "#BioBERT base initial evaluation\n",
    "#path_to_true_dataset = r\"./datasets/dmis-lab/biobert-base-cased-v1.2/val.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/output6/eval_predictions.txt'\n",
    "\n",
    "#Microsoft PubMedBERT initial evaluation\n",
    "#path_to_true_dataset = r\"./datasets/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract/val.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract/eval_predictions.txt'\n",
    "\n",
    "#Microsoft PubMedBERT+PMC initial evaluation\n",
    "#path_to_true_dataset = r\"./datasets/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/val.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/eval_predictions.txt'\n",
    "\n",
    "#BlueBERT base initial evaluation\n",
    "#path_to_true_dataset = r\"./datasets/bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12/val.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12/eval_predictions.txt'\n",
    "\n",
    "#BlueBERT large initial evaluation\n",
    "#path_to_true_dataset = r\"./datasets/bionlp/bluebert_pubmed_uncased_L-24_H-1024_A-16/val.tsv\"\n",
    "#path_to_pred_dataset = r'./NER/bionlp/bluebert_pubmed_uncased_L-24_H-1024_A-16/eval_predictions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf76fb",
   "metadata": {},
   "source": [
    "## Token-Level Evaluation\n",
    "- This ignores differences between B-{tag} and I-{tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ace89a",
   "metadata": {},
   "source": [
    "Import ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcfedefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the corrected (trueified) test set data\n",
    "# DO NOT CHANGE\n",
    "true_tokens, true_tags= [],[]\n",
    "with open(path_to_true_dataset,'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    true_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    true_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5932dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most O\n",
      "amyotrophic O\n",
      "lateral O\n",
      "sclerosis O\n",
      "( O\n",
      "ALS O\n",
      ") O\n",
      "cases O\n",
      "are O\n",
      "considered O\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(true_tokens[x],true_tags[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e250288",
   "metadata": {},
   "source": [
    "Import the comparison set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67ccda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the predicted data (final custom dataset)\n",
    "import csv\n",
    "with open(path_to_pred_dataset,'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    \n",
    "    #for row in reader:\n",
    "    #    if len(row)>1:\n",
    "    #        print(row[0],row[1])\n",
    "    #    else:\n",
    "    #        print('')\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fa834b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most O\n",
      "amyotrophic O\n",
      "lateral O\n",
      "sclerosis O\n",
      "( O\n",
      "ALS O\n",
      ") O\n",
      "cases O\n",
      "are O\n",
      "considered O\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(pred_tokens[x],pred_tags[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e72dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30807 30807\n",
      "30807 30807\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_tokens),len(true_tokens))\n",
    "print(len(pred_tags),len(true_tags))\n",
    "#Some of the sentences were combined when fixing the test set so there are now different number of sentences and different sizes of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8711157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tag(pred_tag,true_tag):\n",
    "    comparison_types = [\"mismatch\",\"skipped_annotations\",\n",
    "                    \"loc_fn\",\"loc_fp\",\n",
    "                    \"stat_fn\",\"stat_fp\",\n",
    "                    \"date_fn\",\"date_fp\",\n",
    "                    \"ethn_fn\",\"ethn_fp\",\n",
    "                    \"sex_fn\",\"sex_fp\",\n",
    "                    \"dz_fn\",\"dz_fp\",\n",
    "                    \"abrv_fn\",\"abrv_fp\",\n",
    "                    \"epi_fn\",\"epi_fp\"]\n",
    "\n",
    "    comparison = dict.fromkeys(comparison_types, 0)\n",
    "    \n",
    "    if pred_tag != true_tag:\n",
    "        #This will fn everything, including ones that mismatch from I-LOC -> B-LOC, the others won't\n",
    "        comparison[\"mismatch\"]+=1\n",
    "        \n",
    "        #False positives\n",
    "        if 'LOC' in pred_tag and 'LOC' not in true_tag:\n",
    "            comparison[\"loc_fp\"]+=1\n",
    "        elif 'DIS' in pred_tag and 'DIS' not in true_tag:\n",
    "            comparison[\"dz_fp\"]+=1\n",
    "        elif 'ABRV' in pred_tag and 'ABRV' not in true_tag:\n",
    "            comparison[\"abrv_fp\"]+=1\n",
    "        elif 'DATE' in pred_tag and 'DATE' not in true_tag:\n",
    "            comparison[\"date_fp\"]+=1\n",
    "        elif 'ETHN' in pred_tag and 'ETHN' not in true_tag:\n",
    "            comparison[\"ethn_fp\"]+=1\n",
    "        elif 'SEX' in pred_tag and 'SEX' not in true_tag:\n",
    "            comparison[\"sex_fp\"]+=1\n",
    "        elif 'STAT' in pred_tag and 'STAT' not in true_tag:\n",
    "            comparison[\"stat_fp\"]+=1\n",
    "        elif 'EPI' in pred_tag and 'EPI' not in true_tag:\n",
    "            comparison[\"epi_fp\"]+=1\n",
    "        \n",
    "        #False negatives\n",
    "        if 'LOC' in true_tag and 'LOC' not in pred_tag:\n",
    "            comparison[\"loc_fn\"]+=1\n",
    "        elif 'DIS' in true_tag and 'DIS' not in pred_tag:\n",
    "            comparison[\"dz_fn\"]+=1\n",
    "        elif 'ABRV' in true_tag and 'ABRV' not in pred_tag:\n",
    "            comparison[\"abrv_fn\"]+=1\n",
    "        elif 'DATE' in true_tag and 'DATE' not in pred_tag:\n",
    "            comparison[\"date_fn\"]+=1\n",
    "        elif 'ETHN' in true_tag and 'ETHN' not in pred_tag:\n",
    "            comparison[\"ethn_fn\"]+=1\n",
    "        elif 'SEX' in true_tag and 'SEX' not in pred_tag:\n",
    "            comparison[\"sex_fn\"]+=1\n",
    "        elif 'STAT' in true_tag and 'STAT' not in pred_tag:\n",
    "            comparison[\"stat_fn\"]+=1\n",
    "        elif 'EPI' in true_tag and 'EPI' not in pred_tag:\n",
    "            comparison[\"epi_fn\"]+=1\n",
    "        return comparison\n",
    "    else:\n",
    "        return comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68b826",
   "metadata": {},
   "source": [
    "Iterate through all tokens and labels but also accounts for small mismatches (off by one) in the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a268fb85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uh oh--> true_idx: 4395 , pred_idx: 4395\n",
      "α3 [alpha]3\n",
      "uh oh--> true_idx: 4397 , pred_idx: 4397\n",
      "α4 [alpha]4\n",
      "uh oh--> true_idx: 4398 , pred_idx: 4398\n",
      "α5 [alpha]5\n",
      "uh oh--> true_idx: 4562 , pred_idx: 4562\n",
      "β01 [beta]01\n",
      "uh oh--> true_idx: 5737 , pred_idx: 5737\n",
      "μm [mu]m\n",
      "uh oh--> true_idx: 5748 , pred_idx: 5748\n",
      "μm [mu]m\n",
      "uh oh--> true_idx: 6226 , pred_idx: 6226\n",
      "11β0 11[beta]0\n",
      "uh oh--> true_idx: 6254 , pred_idx: 6254\n",
      "11β0 11[beta]0\n",
      "uh oh--> true_idx: 6275 , pred_idx: 6275\n",
      "μg [mu]g\n",
      "uh oh--> true_idx: 6297 , pred_idx: 6297\n",
      "11β0 11[beta]0\n",
      "uh oh--> true_idx: 22835 , pred_idx: 22835\n",
      "α [alpha]\n",
      "mismatch 253\n",
      "skipped_annotations 11\n",
      "loc_fn 65\n",
      "loc_fp 18\n",
      "stat_fn 68\n",
      "stat_fp 19\n",
      "date_fn 2\n",
      "date_fp 7\n",
      "ethn_fn 5\n",
      "ethn_fp 26\n",
      "sex_fn 1\n",
      "sex_fp 3\n",
      "dz_fn 0\n",
      "dz_fp 0\n",
      "abrv_fn 0\n",
      "abrv_fp 0\n",
      "epi_fn 9\n",
      "epi_fp 9\n"
     ]
    }
   ],
   "source": [
    "efficacy_types = [\"mismatch\",\"skipped_annotations\",\n",
    "                    \"loc_fn\",\"loc_fp\",\n",
    "                    \"stat_fn\",\"stat_fp\",\n",
    "                    \"date_fn\",\"date_fp\",\n",
    "                    \"ethn_fn\",\"ethn_fp\",\n",
    "                    \"sex_fn\",\"sex_fp\",\n",
    "                    \"dz_fn\",\"dz_fp\",\n",
    "                    \"abrv_fn\",\"abrv_fp\",\n",
    "                    \"epi_fn\",\"epi_fp\"]\n",
    "efficacy_stats = dict.fromkeys(efficacy_types, 0)\n",
    "\n",
    "true_idx, pred_idx=0,0\n",
    "\n",
    "while pred_idx<len(pred_tokens) and true_idx<len(true_tokens):\n",
    "    if true_tokens[true_idx] != pred_tokens[pred_idx]:\n",
    "        if true_tokens[true_idx+1] == pred_tokens[pred_idx]:\n",
    "            true_idx+=1\n",
    "            #compare\n",
    "            comparison = compare_tag(pred_tags[pred_idx],true_tags[true_idx])\n",
    "            for entry in efficacy_types:\n",
    "                efficacy_stats[entry]+=comparison[entry]\n",
    "            pred_idx+=1\n",
    "            true_idx+=1\n",
    "        elif true_tokens[true_idx] == pred_tokens[pred_idx+1]:\n",
    "            pred_idx+=1\n",
    "            #compare\n",
    "            comparison = compare_tag(pred_tags[pred_idx],true_tags[true_idx])\n",
    "            for entry in efficacy_types:\n",
    "                efficacy_stats[entry]+=comparison[entry]\n",
    "            \n",
    "            pred_idx+=1\n",
    "            true_idx+=1\n",
    "        \n",
    "        else:\n",
    "            print('uh oh-->','true_idx:',true_idx,', pred_idx:',pred_idx)\n",
    "            print(true_tokens[true_idx],pred_tokens[pred_idx])\n",
    "            efficacy_stats[\"skipped_annotations\"]+=1\n",
    "            pred_idx+=1\n",
    "            true_idx+=1\n",
    "            #skip compare\n",
    "    else:\n",
    "        #compare\n",
    "        comparison = compare_tag(pred_tags[pred_idx],true_tags[true_idx])\n",
    "        for entry in efficacy_types:\n",
    "            efficacy_stats[entry]+=comparison[entry]\n",
    "        \n",
    "        pred_idx+=1\n",
    "        true_idx+=1\n",
    "            \n",
    "for k,v in efficacy_stats.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3a6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of true positives\n",
    "def count_tags(tags):\n",
    "    tag_types = ['LOC', 'ETHN', 'DATE', 'STAT', 'SEX','DIS','ABRV','EPI']\n",
    "    tp = dict.fromkeys(tag_types, 0)\n",
    "    \n",
    "    for tag in tags:\n",
    "        for tag_type in tag_types:\n",
    "            if tag_type in tag:\n",
    "                tp[tag_type]+=1\n",
    "                ''' This is equivalent to doing:\n",
    "                    ```\n",
    "                    if 'LOC' in tag:\n",
    "                        l+=1\n",
    "                    elif 'DIS' in tag:\n",
    "                        d+=1\n",
    "                    elif 'ABRV' in tag:\n",
    "                        a+=1\n",
    "                    elif 'STAT' in tag:\n",
    "                        s+=1\n",
    "                    elif 'EPI' in tag:\n",
    "                        e+=1\n",
    "                    ```\n",
    "                    in the previous code\n",
    "                '''\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8b9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(tp,fp,fn):\n",
    "    if tp==0:\n",
    "        return {'precision':0.0,'recall':0.0,'F1':0.0}\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        F1=(2*precision*recall)/(precision+recall)\n",
    "        return {'precision':precision,'recall':recall,'F1':F1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f649f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-level overall precision 0.9213051823416507\n",
      "token-level overall recall 0.8648648648648649\n",
      "token-level overall F1 0.892193308550186\n",
      "\n",
      "disease classification precision 0.0\n",
      "disease classification recall 0.0\n",
      "disease classification F1 0.0\n",
      "\n",
      "abrv classification precision 0.0\n",
      "abrv classification recall 0.0\n",
      "abrv classification F1 0.0\n",
      "\n",
      "location classification precision 0.9357142857142857\n",
      "location classification recall 0.8012232415902141\n",
      "location classification F1 0.8632619439868204\n",
      "\n",
      "date classification precision 0.9615384615384616\n",
      "date classification recall 0.9887005649717514\n",
      "date classification F1 0.9749303621169916\n",
      "\n",
      "ethnicity/nationality/race precision 0.559322033898305\n",
      "ethnicity/nationality/race recall 0.868421052631579\n",
      "ethnicity/nationality/race F1 0.6804123711340205\n",
      "\n",
      "biological sex classification precision 0.9625\n",
      "biological sex classification recall 0.9871794871794872\n",
      "biological sex classification F1 0.9746835443037976\n",
      "\n",
      "epi type classification precision 0.9623430962343096\n",
      "epi type classification recall 0.9623430962343096\n",
      "epi type classification F1 0.9623430962343096\n",
      "\n",
      "epi rate identification precision 0.905940594059406\n",
      "epi rate identification recall 0.7290836653386454\n",
      "epi rate identification F1 0.8079470198675497\n",
      "\n",
      "overall accuracy 0.9917846473567996\n"
     ]
    }
   ],
   "source": [
    "#True Positives\n",
    "tp = count_tags(true_tags)\n",
    "\n",
    "#ALl stats\n",
    "loc_stats = get_stats(tp[\"LOC\"],efficacy_stats[\"loc_fp\"],efficacy_stats[\"loc_fn\"])\n",
    "stat_stats = get_stats(tp[\"STAT\"],efficacy_stats[\"stat_fp\"],efficacy_stats[\"stat_fn\"])\n",
    "epi_stats = get_stats(tp[\"EPI\"],efficacy_stats[\"epi_fp\"],efficacy_stats[\"epi_fn\"])\n",
    "sex_stats = get_stats(tp[\"SEX\"],efficacy_stats[\"sex_fp\"],efficacy_stats[\"sex_fn\"])\n",
    "ethn_stats = get_stats(tp[\"ETHN\"],efficacy_stats[\"ethn_fp\"],efficacy_stats[\"ethn_fn\"])\n",
    "date_stats = get_stats(tp[\"DATE\"],efficacy_stats[\"date_fp\"],efficacy_stats[\"date_fn\"])\n",
    "dz_stats = get_stats(tp[\"DIS\"],efficacy_stats[\"dz_fp\"],efficacy_stats[\"dz_fn\"])\n",
    "abrv_stats = get_stats(tp[\"ABRV\"],efficacy_stats[\"abrv_fp\"],efficacy_stats[\"abrv_fn\"])\n",
    "\n",
    "#Overall\n",
    "overall_tp = sum([val for val in tp.values()])\n",
    "\n",
    "fp_types = [etype for etype in efficacy_types if 'fp' in etype]\n",
    "overall_fp = sum([efficacy_stats[fp_type] for fp_type in fp_types])\n",
    "\n",
    "fn_types = [etype for etype in efficacy_types if 'fn' in etype]\n",
    "overall_fn = sum([efficacy_stats[fn_type] for fn_type in fn_types])\n",
    "\n",
    "overall_stats = get_stats(overall_tp, overall_fp, overall_fn)\n",
    "\n",
    "for k,v in overall_stats.items():\n",
    "    print('token-level overall',k,v)\n",
    "print()\n",
    "for k,v in dz_stats.items():\n",
    "    print('disease classification',k,v)\n",
    "print()\n",
    "for k,v in abrv_stats.items():\n",
    "    print('abrv classification',k,v)\n",
    "print()\n",
    "for k,v in loc_stats.items():\n",
    "    print('location classification',k,v)\n",
    "print()\n",
    "for k,v in date_stats.items():\n",
    "    print('date classification',k,v)\n",
    "print()\n",
    "for k,v in ethn_stats.items():\n",
    "    print('ethnicity/nationality/race',k,v)\n",
    "print()\n",
    "for k,v in sex_stats.items():\n",
    "    print('biological sex classification',k,v)\n",
    "print()\n",
    "for k,v in epi_stats.items():\n",
    "    print('epi type classification',k,v)\n",
    "print()\n",
    "for k,v in stat_stats.items():\n",
    "    print('epi rate identification',k,v)\n",
    "print()\n",
    "print('overall accuracy',1-(efficacy_stats[\"mismatch\"])/(len(true_tags)-efficacy_stats[\"skipped_annotations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aeac48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC 262 Relative weight: 0.27291666666666664\n",
      "ETHN 33 Relative weight: 0.034375\n",
      "DATE 175 Relative weight: 0.18229166666666666\n",
      "STAT 183 Relative weight: 0.190625\n",
      "SEX 77 Relative weight: 0.08020833333333334\n",
      "DIS 0 Relative weight: 0.0\n",
      "ABRV 0 Relative weight: 0.0\n",
      "EPI 230 Relative weight: 0.23958333333333334\n",
      "Sanity Check:  1.0\n"
     ]
    }
   ],
   "source": [
    "sanity_check=0.0\n",
    "for k,v in tp.items():\n",
    "    print(k,v,'Relative weight:',v/overall_tp)\n",
    "    sanity_check+=v/overall_tp\n",
    "print('Sanity Check: ',sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd57865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda05dc",
   "metadata": {},
   "source": [
    "## Entity-Level Evaluation (with seqeval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb1780",
   "metadata": {},
   "source": [
    "Must re-input the comparison files because this is list of lists of tags, not just list of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c52b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ground truth, do not change\n",
    "y_true= []\n",
    "#'epi_test_setV2-corrected.tsv'\n",
    "with open(path_to_true_dataset,'r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentences_tags=[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                y_true.append(sentences_tags.copy())\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2194fd7",
   "metadata": {},
   "source": [
    "Import comparison set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c8d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the predicted data\n",
    "y_pred= []\n",
    "with open(path_to_pred_dataset,'r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    sentences_tags=[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                y_pred.append(sentences_tags.copy())\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c17dcee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206 1209\n"
     ]
    }
   ],
   "source": [
    "print(len(y_true),len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a05e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 5 89\n",
      "89 89\n",
      "84 15 99\n",
      "99 99\n",
      "76 7 83\n",
      "83 83\n"
     ]
    }
   ],
   "source": [
    "#Correct the mismatch\n",
    "for i in range(min(len(y_pred),len(y_true))):\n",
    "    if len(y_pred[i]) != len(y_true[i]):\n",
    "        print(len(y_pred[i]), len(y_pred[i+1]), len(y_true[i]))\n",
    "        if len(y_pred[i+1])+len(y_pred[i]) == len(y_true[i]):\n",
    "            y_pred[i]+=y_pred[i+1]\n",
    "            y_pred.pop(i+1)\n",
    "            print(len(y_pred[i]), len(y_true[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b275ff42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206 1206\n"
     ]
    }
   ],
   "source": [
    "print(len(y_true),len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c988c5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "def get_seqevalmetrics(y_true,y_pred):\n",
    "    return {\n",
    "            \"precision\": precision_score(y_true, y_pred),\n",
    "            \"recall\": recall_score(y_true, y_pred),\n",
    "            \"f1\": f1_score(y_true, y_pred),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e74d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL {'precision': 0.8235294117647058, 'recall': 0.8506944444444444, 'f1': 0.8368915456874466}\n"
     ]
    }
   ],
   "source": [
    "print('OVERALL',get_seqevalmetrics(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed00e61",
   "metadata": {},
   "source": [
    "### Get individual entity types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d29e8",
   "metadata": {},
   "source": [
    "This will normalize all other entities except for a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c0a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "#LOCATION\n",
    "y_true_loc = deepcopy(y_true)\n",
    "y_pred_loc = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'LOC' not in y_pred[i][j]:\n",
    "            y_pred_loc[i][j] = 'O'\n",
    "        if 'LOC' not in y_true[i][j]:\n",
    "            y_true_loc[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68f3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPI IDENTIFIER\n",
    "y_true_epi = deepcopy(y_true)\n",
    "y_pred_epi = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'EPI' not in y_true[i][j]:\n",
    "            y_true_epi[i][j] = 'O'\n",
    "        if 'EPI' not in y_pred[i][j]:\n",
    "            y_pred_epi[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ec918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPI Rate\n",
    "y_true_stat = deepcopy(y_true)\n",
    "y_pred_stat = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'STAT' not in y_true[i][j]:\n",
    "            y_true_stat[i][j] = 'O'\n",
    "        if 'STAT' not in y_pred[i][j]:\n",
    "            y_pred_stat[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5349d996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DATE\n",
    "y_true_date = deepcopy(y_true)\n",
    "y_pred_date = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'DATE' not in y_true[i][j]:\n",
    "            y_true_date[i][j] = 'O'\n",
    "        if 'DATE' not in y_pred[i][j]:\n",
    "            y_pred_date[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7b27fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEX\n",
    "y_true_sex = deepcopy(y_true)\n",
    "y_pred_sex = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'SEX' not in y_true[i][j]:\n",
    "            y_true_sex[i][j] = 'O'\n",
    "        if 'SEX' not in y_pred[i][j]:\n",
    "            y_pred_sex[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "408d53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETHN\n",
    "y_true_ethn = deepcopy(y_true)\n",
    "y_pred_ethn = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'ETHN' not in y_true[i][j]:\n",
    "            y_true_ethn[i][j] = 'O'\n",
    "        if 'ETHN' not in y_pred[i][j]:\n",
    "            y_pred_ethn[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e65d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIS\n",
    "y_true_dz = deepcopy(y_true)\n",
    "y_pred_dz = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'DIS' not in y_true[i][j]:\n",
    "            y_true_dz[i][j] = 'O'\n",
    "        if 'DIS' not in y_pred[i][j]:\n",
    "            y_pred_dz[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30777489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRV\n",
    "y_true_abrv = deepcopy(y_true)\n",
    "y_pred_abrv = deepcopy(y_pred)\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if 'ABRV' not in y_true[i][j]:\n",
    "            y_true_abrv[i][j] = 'O'\n",
    "        if 'ABRV' not in y_pred[i][j]:\n",
    "            y_pred_abrv[i][j] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fe0ed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzkariampuzha/.local/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wzkariampuzha/.local/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wzkariampuzha/.local/lib/python3.6/site-packages/seqeval/metrics/v1.py:160: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, 'true nor predicted', 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL precision 0.8235294117647058\n",
      "OVERALL recall 0.8506944444444444\n",
      "OVERALL f1 0.8368915456874466\n",
      "\n",
      "LOCATION precision 0.7654320987654321\n",
      "LOCATION recall 0.7607361963190185\n",
      "LOCATION f1 0.7630769230769231\n",
      "\n",
      "EPI IDENTIFIER precision 0.9054726368159204\n",
      "EPI IDENTIFIER recall 0.9528795811518325\n",
      "EPI IDENTIFIER f1 0.9285714285714286\n",
      "\n",
      "EPI RATE precision 0.6875\n",
      "EPI RATE recall 0.559322033898305\n",
      "EPI RATE f1 0.6168224299065421\n",
      "\n",
      "DATE precision 0.8571428571428571\n",
      "DATE recall 0.8888888888888888\n",
      "DATE f1 0.8727272727272727\n",
      "\n",
      "SEX precision 0.9493670886075949\n",
      "SEX recall 0.9868421052631579\n",
      "SEX f1 0.967741935483871\n",
      "\n",
      "ETHN precision 0.5714285714285714\n",
      "ETHN recall 0.8484848484848485\n",
      "ETHN f1 0.6829268292682927\n",
      "\n",
      "DIS precision 0.0\n",
      "DIS recall 0.0\n",
      "DIS f1 0.0\n",
      "\n",
      "ABRV precision 0.0\n",
      "ABRV recall 0.0\n",
      "ABRV f1 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get all as a single printout\n",
    "entity_level = {'OVERALL':get_seqevalmetrics(y_true,y_pred),\n",
    "                'LOCATION':get_seqevalmetrics(y_true_loc,y_pred_loc),\n",
    "                'EPI IDENTIFIER':get_seqevalmetrics(y_true_epi,y_pred_epi),\n",
    "                'EPI RATE':get_seqevalmetrics(y_true_stat,y_pred_stat),\n",
    "                'DATE':get_seqevalmetrics(y_true_date,y_pred_date),\n",
    "                'SEX':get_seqevalmetrics(y_true_sex,y_pred_sex),\n",
    "                'ETHN':get_seqevalmetrics(y_true_ethn,y_pred_ethn),\n",
    "                'DIS':get_seqevalmetrics(y_true_dz,y_pred_dz),\n",
    "                'ABRV':get_seqevalmetrics(y_true_abrv,y_pred_abrv)}\n",
    "\n",
    "for typ,metrics in entity_level.items():\n",
    "    for stat,num in metrics.items():\n",
    "        print(typ,stat,num)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff91e19",
   "metadata": {},
   "source": [
    "diagnose why there was a length mismatch between the predicted and true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17a93d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sentence where there was the first mismatch (line 7000ish)\n",
    "x = [\"The\",\n",
    "\"clinician\",\n",
    "\"should\",\n",
    "\"be\",\n",
    "\"alert\",\n",
    "\"to\",\n",
    "\"recognize\",\n",
    "\"several\",\n",
    "\"factors\",\n",
    "\"that\",\n",
    "\"may\",\n",
    "\"maximize\",\n",
    "\"renal\",\n",
    "\"dysfunction\",\n",
    "\"and\",\n",
    "\"contribute\",\n",
    "\"to\",\n",
    "\"the\",\n",
    "\"increased\",\n",
    "\"incidence\",\n",
    "\"of\",\n",
    "\"nephrotoxicity\",\n",
    "\"associated\",\n",
    "\"with\",\n",
    "\"these\",\n",
    "\"drugs\",\n",
    "\",\",\n",
    "\"such\",\n",
    "\"as\",\n",
    "\"intravascular\",\n",
    "\"volume\",\n",
    "\"depletion\",\n",
    "\",\",\n",
    "\"the\",\n",
    "\"associated\",\n",
    "\"use\",\n",
    "\"of\",\n",
    "\"nonchemotherapeutic\",\n",
    "\"nephrotoxic\",\n",
    "\"drugs\",\n",
    "\"(\",\n",
    "\"analgesics\",\n",
    "\",\",\n",
    "\"antibiotics\",\n",
    "\",\",\n",
    "\"proton\",\n",
    "\"pump\",\n",
    "\"inhibitors\",\n",
    "\",\",\n",
    "\"and\",\n",
    "\"bone\",\n",
    "\"-\",\n",
    "\"targeted\",\n",
    "\"therapies\",\n",
    "\")\",\n",
    "\",\",\n",
    "\"radiographic\",\n",
    "\"ionic\",\n",
    "\"contrast\",\n",
    "\"media\",\n",
    "\"or\",\n",
    "\"radiation\",\n",
    "\"therapy\",\n",
    "\",\",\n",
    "\"urinary\",\n",
    "\"tract\",\n",
    "\"obstruction\",\n",
    "\",\",\n",
    "\"and\",\n",
    "\"intrinsic\",\n",
    "\"renal\",\n",
    "\"disease\",\n",
    "\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1c5d123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
    "len(tokenizer.tokenize(' '.join(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bf988",
   "metadata": {},
   "source": [
    "Thus the mismatch error is due to tokenizing errors since the max sequence length was 100. Increasing max sequence length to 128 which covers 99.676% of all sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

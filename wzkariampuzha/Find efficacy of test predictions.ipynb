{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f22c8d6",
   "metadata": {},
   "source": [
    "Goals: \n",
    "- Find out precision, recall, F1 for each tag class in predictions compared to test set on a token level, not entity level.\n",
    "- Can also use this to compare the unmodified test set to the modified test set\n",
    "- This ignores differences between B-{tag} and I-{tag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ceb9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport csv\\nwith open(\\'./epi_test_setV2-corrected.tsv\\',\\'r\\') as f:\\n    reader = csv.reader(f, delimiter=\"\\t\")\\n    pred_tokens = [row[0] for row in reader if len(row)>1]\\n    f.seek(0)\\n    pred_tags = [row[1] for row in reader if len(row)>1]\\nf.close()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the the original unmodified test set\n",
    "'''\n",
    "import csv\n",
    "with open('./epi_test_setV2-corrected.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6010cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the predicted data (final custom dataset)\n",
    "import csv\n",
    "with open('./resultsV3.2/test_predictions.txt','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    '''\n",
    "    for row in reader:\n",
    "        if len(row)>1:\n",
    "            print(row[0],row[1])\n",
    "        else:\n",
    "            print('')\n",
    "    '''\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6fa19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport csv\\nwith open(\\'./resultsLargeV3.1/test_predictions.txt\\',\\'r\\') as f:\\n    reader = csv.reader(f, delimiter=\" \")\\n    pred_tokens = [row[0] for row in reader if len(row)>1]\\n    f.seek(0)\\n    pred_tags = [row[1] for row in reader if len(row)>1]\\nf.close()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the predicted data (large dataset)\n",
    "'''\n",
    "import csv\n",
    "with open('./resultsLargeV3.1/test_predictions.txt','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    pred_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    pred_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fa834b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context O\n",
      "Patients O\n",
      "with O\n",
      "pseudohypoparathyroidism O\n",
      "type O\n",
      "1b O\n",
      "( O\n",
      "PHP1b O\n",
      ") O\n",
      "show O\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(pred_tokens[x],pred_tags[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfedefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the corrected (modified) test set data\n",
    "mod_tokens, mod_tags= [],[]\n",
    "with open('./datasets/Large_DatasetV2/test.txt','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \", quoting=csv.QUOTE_NONE)\n",
    "    mod_tokens = [row[0] for row in reader if len(row)>1]\n",
    "    f.seek(0)\n",
    "    mod_tags = [row[1] for row in reader if len(row)>1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5932dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context O\n",
      "Patients O\n",
      "with O\n",
      "pseudohypoparathyroidism O\n",
      "type O\n",
      "1b O\n",
      "( O\n",
      "PHP1b O\n",
      ") O\n",
      "show O\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(mod_tokens[x],mod_tags[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e72dde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13910 13910\n",
      "13910 13910\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_tokens),len(mod_tokens))\n",
    "print(len(pred_tags),len(mod_tags))\n",
    "#Some of the sentences were combined when fixing the test set so there are now different number of sentences and different sizes of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8711157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tag(pred_tag,mod_tag):\n",
    "    \n",
    "    changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem=0,0,0,0,0,0,0,0,0\n",
    "    \n",
    "    if pred_tag != mod_tag:\n",
    "        #This will add everything, including ones that change from I-LOC -> B-LOC, the others won't\n",
    "        changes+=1\n",
    "        \n",
    "        #False positives\n",
    "        if 'LOC' in pred_tag and 'LOC' not in mod_tag:\n",
    "            loc_rem+=1\n",
    "        elif 'DIS' in pred_tag and 'DIS' not in mod_tag:\n",
    "            dz_rem+=1\n",
    "        elif 'STAT' in pred_tag and 'STAT' not in mod_tag:\n",
    "            stat_rem+=1\n",
    "        elif 'EPI' in pred_tag and 'EPI' not in mod_tag:\n",
    "            epi_rem+=1\n",
    "        \n",
    "        #False negatives\n",
    "        if 'LOC' in mod_tag and 'LOC' not in pred_tag:\n",
    "            loc_add+=1\n",
    "        elif 'DIS' in mod_tag and 'DIS' not in pred_tag:\n",
    "            dz_add+=1\n",
    "        elif 'STAT' in mod_tag and 'STAT' not in pred_tag:\n",
    "            stat_add+=1\n",
    "        elif 'EPI' in mod_tag and 'EPI' not in pred_tag:\n",
    "            epi_add+=1\n",
    "        return changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem\n",
    "    else:\n",
    "        return changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a268fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch:  296 \n",
      "loc_fn:  39 \n",
      "loc_fp:  6 \n",
      "stat_fn:  125 \n",
      "stat_fp:  83 \n",
      "dz_fn:  0 \n",
      "dz_fp:  0 \n",
      "epi_fn:  9 \n",
      "epi_fp:  11 \n",
      "skipped annotations:  0\n"
     ]
    }
   ],
   "source": [
    "mismatch, loc_fn, loc_fp, stat_fn, stat_fp, dz_fn, dz_fp, epi_fn,epi_fp=0,0,0,0,0,0,0,0,0\n",
    "mod_idx, pred_idx=0,0\n",
    "skipped_annotations=0\n",
    "\n",
    "while pred_idx<len(pred_tokens) and mod_idx<len(mod_tokens):\n",
    "    if mod_tokens[mod_idx] != pred_tokens[pred_idx]:\n",
    "        if mod_tokens[mod_idx+1] == pred_tokens[pred_idx]:\n",
    "            mod_idx+=1\n",
    "            #compare\n",
    "            changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem = compare_tag(\n",
    "                pred_tags[pred_idx],mod_tags[mod_idx])\n",
    "            mismatch+=changes\n",
    "            loc_fn+=loc_add\n",
    "            loc_fp+=loc_rem\n",
    "            stat_fn+=stat_add\n",
    "            stat_fp+=stat_rem\n",
    "            dz_fn+=dz_add\n",
    "            dz_fp+=dz_rem\n",
    "            epi_fn+=epi_add\n",
    "            epi_fp+=epi_rem\n",
    "            \n",
    "            pred_idx+=1\n",
    "            mod_idx+=1\n",
    "        elif mod_tokens[mod_idx] == pred_tokens[pred_idx+1]:\n",
    "            pred_idx+=1\n",
    "            #compare\n",
    "            changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem = compare_tag(\n",
    "                pred_tags[pred_idx],mod_tags[mod_idx])\n",
    "            mismatch+=changes\n",
    "            loc_fn+=loc_add\n",
    "            loc_fp+=loc_rem\n",
    "            stat_fn+=stat_add\n",
    "            stat_fp+=stat_rem\n",
    "            dz_fn+=dz_add\n",
    "            dz_fp+=dz_rem\n",
    "            epi_fn+=epi_add\n",
    "            epi_fp+=epi_rem\n",
    "            \n",
    "            pred_idx+=1\n",
    "            mod_idx+=1\n",
    "        \n",
    "        else:\n",
    "            print('uh oh-->','mod_idx:',mod_idx,', pred_idx:',pred_idx)\n",
    "            print(mod_tokens[mod_idx],pred_tokens[pred_idx])\n",
    "            skipped_annotations+=1\n",
    "            pred_idx+=1\n",
    "            mod_idx+=1\n",
    "            #skip compare\n",
    "    else:\n",
    "        #compare\n",
    "        changes, loc_add, loc_rem, stat_add, stat_rem, dz_add, dz_rem, epi_add, epi_rem = compare_tag(\n",
    "            pred_tags[pred_idx],mod_tags[mod_idx])\n",
    "        mismatch+=changes\n",
    "        loc_fn+=loc_add\n",
    "        loc_fp+=loc_rem\n",
    "        stat_fn+=stat_add\n",
    "        stat_fp+=stat_rem\n",
    "        dz_fn+=dz_add\n",
    "        dz_fp+=dz_rem\n",
    "        epi_fn+=epi_add\n",
    "        epi_fp+=epi_rem\n",
    "        \n",
    "        pred_idx+=1\n",
    "        mod_idx+=1\n",
    "            \n",
    "\n",
    "print('mismatch: ',mismatch, \n",
    "      '\\nloc_fn: ',loc_fn, \n",
    "      '\\nloc_fp: ',loc_fp, \n",
    "      '\\nstat_fn: ',stat_fn, \n",
    "      '\\nstat_fp: ',stat_fp, \n",
    "      '\\ndz_fn: ',dz_fn, \n",
    "      '\\ndz_fp: ',dz_fp, \n",
    "      '\\nepi_fn: ',epi_fn, \n",
    "      '\\nepi_fp: ',epi_fp,\n",
    "      '\\nskipped annotations: ',int(skipped_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3a6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tags(tags):\n",
    "    l,d,s,e = 0,0,0,0\n",
    "    for tag in tags:\n",
    "        if 'LOC' in tag:\n",
    "            l+=1\n",
    "        elif 'DIS' in tag:\n",
    "            d+=1\n",
    "        elif 'STAT' in tag:\n",
    "            s+=1\n",
    "        elif 'EPI' in tag:\n",
    "            e+=1\n",
    "    return l,d,s,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8b9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(tp,fp,fn):\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    F1=(2*precision*recall)/(precision+recall)\n",
    "    return {'precision':precision,'recall':recall,'F1':F1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f649f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-level overall precision 0.8109640831758034\n",
      "token-level overall recall 0.7126245847176079\n",
      "token-level overall F1 0.7586206896551723\n",
      "\n",
      "location classification precision 0.9491525423728814\n",
      "location classification recall 0.7417218543046358\n",
      "location classification F1 0.8327137546468403\n",
      "\n",
      "statistic identification precision 0.7242524916943521\n",
      "statistic identification recall 0.6355685131195336\n",
      "statistic identification F1 0.6770186335403726\n",
      "\n",
      "epidemiology word classification precision 0.9\n",
      "epidemiology word classification recall 0.9166666666666666\n",
      "epidemiology word classification F1 0.908256880733945\n",
      "\n",
      "overall accuracy 0.9787203450754852\n"
     ]
    }
   ],
   "source": [
    "loc_tp, dz_tp, stat_tp, epi_tp = count_tags(mod_tags)\n",
    "#dz_stats = get_stats(dz_tp,dz_fp,dz_fn)\n",
    "loc_stats = get_stats(loc_tp,loc_fp,loc_fn)\n",
    "stat_stats = get_stats(stat_tp,stat_fp,stat_fn)\n",
    "epi_stats = get_stats(epi_tp,epi_fp,epi_fn)\n",
    "overall_stats = get_stats(loc_tp+dz_tp+stat_tp+epi_tp, loc_fp+dz_fp+stat_fp+epi_fp, dz_fn+loc_fn+stat_fn+epi_fn)\n",
    "\n",
    "\n",
    "for k,v in overall_stats.items():\n",
    "    print('token-level overall',k,v)\n",
    "print('')\n",
    "#for k,v in dz_stats.items():\n",
    "#    print('disease classification',k,v)\n",
    "#print('')\n",
    "for k,v in loc_stats.items():\n",
    "    print('location classification',k,v)\n",
    "print('')\n",
    "for k,v in stat_stats.items():\n",
    "    print('statistic identification',k,v)\n",
    "print('')\n",
    "for k,v in epi_stats.items():\n",
    "    print('epidemiology word classification',k,v)\n",
    "print('')\n",
    "print('overall accuracy',1-(mismatch)/(len(mod_tags)-skipped_annotations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

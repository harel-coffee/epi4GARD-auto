{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 11:32:48.389768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-22 11:32:48.389791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "ner = pipeline('ner',aggregation_strategy='first')\n",
    "sequence = \"Lysosomal storage diseases (LSDs) are a group of inherited metabolic disorders individually considered as rare, and few data on its prevalence has been reported in the literature. The overall birth prevalence of the 29 different LSDs studied in the Portuguese population was calculated to be 25/100000 live births, twice the prevalence previously described in Australia and in The Netherlands. The comparison of the prevalence profile of the LSDs presenting a prevalence higher than 0.5/100000 in the Portuguese, Dutch and Australian populations showed, in the Portuguese, the existence of a higher prevalence of GM2 gangliosidoses (B variant), mucolipidoses (II and III), Niemman-Pick type C and metachromatic leukodystrophy (MLD), and a lower prevalence of Pompe and Fabry. The highest prevalence value for a single LSD is the one of GM2 gangliosidoses (B variant), corresponding to 3/100000, a value which is significantly higher than the prevalence of the most frequent LSD in Dutch, Pompe disease (2/100000) and Australians, Gaucher's disease (GD) (1.8/100000). It is worth noting that the highest prevalence of GM2 gangliosidoses found in the Portuguese is mainly due to the existence of a unique subtype, the rare juvenile B1 variant.\"\n",
    "seq2 = 'Salla disease, which is very rare elsewhere, was the fourth most common, stemming from a founder mutation in the Salla region of northern Finland brought to Sweden by immigration. Conclusion: The collective incidence of LSDs in Sweden was essentially equal to other European countries, but with a somewhat different disease pattern.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.3989161,\n",
       "  'word': 'Salla',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.98992246,\n",
       "  'word': 'Salla',\n",
       "  'start': 113,\n",
       "  'end': 118},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9994418,\n",
       "  'word': 'Finland',\n",
       "  'start': 138,\n",
       "  'end': 145},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9993529,\n",
       "  'word': 'Sweden',\n",
       "  'start': 157,\n",
       "  'end': 163},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.8880484,\n",
       "  'word': 'LSDs',\n",
       "  'start': 220,\n",
       "  'end': 224},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9996027,\n",
       "  'word': 'Sweden',\n",
       "  'start': 228,\n",
       "  'end': 234},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99863356,\n",
       "  'word': 'European',\n",
       "  'start': 266,\n",
       "  'end': 274}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ner(sequence)\n",
    "ner(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dmis-lab/biobert-large-cased-v1.1 were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-large-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LABEL_1',\n",
       "  'score': 0.5531621,\n",
       "  'word': 'salla',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.7127989,\n",
       "  'word': 'disease',\n",
       "  'start': 6,\n",
       "  'end': 13},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.60013914,\n",
       "  'word': ',',\n",
       "  'start': 13,\n",
       "  'end': 14},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5715016,\n",
       "  'word': 'which',\n",
       "  'start': 15,\n",
       "  'end': 20},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6100735,\n",
       "  'word': 'is',\n",
       "  'start': 21,\n",
       "  'end': 23},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5171082,\n",
       "  'word': 'very',\n",
       "  'start': 24,\n",
       "  'end': 28},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5584344,\n",
       "  'word': 'rare',\n",
       "  'start': 29,\n",
       "  'end': 33},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6058365,\n",
       "  'word': 'elsewhere',\n",
       "  'start': 34,\n",
       "  'end': 43},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.610298,\n",
       "  'word': ',',\n",
       "  'start': 43,\n",
       "  'end': 44},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.66050404,\n",
       "  'word': 'was',\n",
       "  'start': 45,\n",
       "  'end': 48},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6446863,\n",
       "  'word': 'the',\n",
       "  'start': 49,\n",
       "  'end': 52},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.578082,\n",
       "  'word': 'fourth',\n",
       "  'start': 53,\n",
       "  'end': 59},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.67701364,\n",
       "  'word': 'most',\n",
       "  'start': 60,\n",
       "  'end': 64},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6552479,\n",
       "  'word': 'common',\n",
       "  'start': 65,\n",
       "  'end': 71},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.61488295,\n",
       "  'word': ',',\n",
       "  'start': 71,\n",
       "  'end': 72},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.7008669,\n",
       "  'word': 'stemming',\n",
       "  'start': 73,\n",
       "  'end': 81},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5648862,\n",
       "  'word': 'from',\n",
       "  'start': 82,\n",
       "  'end': 86},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.59708375,\n",
       "  'word': 'a',\n",
       "  'start': 87,\n",
       "  'end': 88},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.52037793,\n",
       "  'word': 'founder',\n",
       "  'start': 89,\n",
       "  'end': 96},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6907245,\n",
       "  'word': 'mutation',\n",
       "  'start': 97,\n",
       "  'end': 105},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.53812224,\n",
       "  'word': 'in',\n",
       "  'start': 106,\n",
       "  'end': 108},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.55104256,\n",
       "  'word': 'the',\n",
       "  'start': 109,\n",
       "  'end': 112},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.50729805,\n",
       "  'word': 'salla',\n",
       "  'start': 113,\n",
       "  'end': 118},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.51952666,\n",
       "  'word': 'region',\n",
       "  'start': 119,\n",
       "  'end': 125},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.5277117,\n",
       "  'word': 'of',\n",
       "  'start': 126,\n",
       "  'end': 128},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6189437,\n",
       "  'word': 'northern',\n",
       "  'start': 129,\n",
       "  'end': 137},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.64193726,\n",
       "  'word': 'finland',\n",
       "  'start': 138,\n",
       "  'end': 145},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.5534947,\n",
       "  'word': 'brought',\n",
       "  'start': 146,\n",
       "  'end': 153},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6866335,\n",
       "  'word': 'to',\n",
       "  'start': 154,\n",
       "  'end': 156},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.65256435,\n",
       "  'word': 'sweden',\n",
       "  'start': 157,\n",
       "  'end': 163},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.519617,\n",
       "  'word': 'by',\n",
       "  'start': 164,\n",
       "  'end': 166},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.552318,\n",
       "  'word': 'immigration',\n",
       "  'start': 167,\n",
       "  'end': 178},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.60948926,\n",
       "  'word': '.',\n",
       "  'start': 178,\n",
       "  'end': 179},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.56213427,\n",
       "  'word': 'conclusion',\n",
       "  'start': 180,\n",
       "  'end': 190},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.50310117,\n",
       "  'word': ':',\n",
       "  'start': 190,\n",
       "  'end': 191},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6813444,\n",
       "  'word': 'the',\n",
       "  'start': 192,\n",
       "  'end': 195},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.56093735,\n",
       "  'word': 'collective',\n",
       "  'start': 196,\n",
       "  'end': 206},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.596548,\n",
       "  'word': 'incidence',\n",
       "  'start': 207,\n",
       "  'end': 216},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.602203,\n",
       "  'word': 'of',\n",
       "  'start': 217,\n",
       "  'end': 219},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5294007,\n",
       "  'word': 'lsds',\n",
       "  'start': 220,\n",
       "  'end': 224},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.5872146,\n",
       "  'word': 'in',\n",
       "  'start': 225,\n",
       "  'end': 227},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6594107,\n",
       "  'word': 'sweden',\n",
       "  'start': 228,\n",
       "  'end': 234},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5956845,\n",
       "  'word': 'was',\n",
       "  'start': 235,\n",
       "  'end': 238},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.52904904,\n",
       "  'word': 'essentially',\n",
       "  'start': 239,\n",
       "  'end': 250},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6064229,\n",
       "  'word': 'equal',\n",
       "  'start': 251,\n",
       "  'end': 256},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.5735348,\n",
       "  'word': 'to',\n",
       "  'start': 257,\n",
       "  'end': 259},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.7817802,\n",
       "  'word': 'other',\n",
       "  'start': 260,\n",
       "  'end': 265},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6347568,\n",
       "  'word': 'european',\n",
       "  'start': 266,\n",
       "  'end': 274},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.6092996,\n",
       "  'word': 'countries',\n",
       "  'start': 275,\n",
       "  'end': 284},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6373742,\n",
       "  'word': ',',\n",
       "  'start': 284,\n",
       "  'end': 285},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.5636706,\n",
       "  'word': 'but',\n",
       "  'start': 286,\n",
       "  'end': 289},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.58178145,\n",
       "  'word': 'with',\n",
       "  'start': 290,\n",
       "  'end': 294},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.60949206,\n",
       "  'word': 'a',\n",
       "  'start': 295,\n",
       "  'end': 296},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.559198,\n",
       "  'word': 'somewhat',\n",
       "  'start': 297,\n",
       "  'end': 305},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.50271624,\n",
       "  'word': 'different',\n",
       "  'start': 306,\n",
       "  'end': 315},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.6330393,\n",
       "  'word': 'disease',\n",
       "  'start': 316,\n",
       "  'end': 323},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': 0.5174908,\n",
       "  'word': 'pattern',\n",
       "  'start': 324,\n",
       "  'end': 331},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': 0.60949624,\n",
       "  'word': '.',\n",
       "  'start': 331,\n",
       "  'end': 332}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biobert = 'dmis-lab/biobert-large-cased-v1.1'\n",
    "bioner = pipeline('ner', biobert,aggregation_strategy='first')\n",
    "#bioner(sequence)\n",
    "bioner(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': 0.62166363,\n",
       "  'word': 'Sal',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.8871105,\n",
       "  'word': 'Salla',\n",
       "  'start': None,\n",
       "  'end': None}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from transformers import BertForTokenClassification\n",
    "from transformers import BertConfig, AutoModelForTokenClassification, BertTokenizer\n",
    "custom_path = \"./named-entity-recognition/output/Location/\"\n",
    "config = BertConfig.from_json_file(str(custom_path+'config.json'))\n",
    "#tokenizer = BertTokenizer.from_pretrained(custom_path)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "custommodel = AutoModelForTokenClassification.from_pretrained(custom_path,config=config)\n",
    "customNER = pipeline('ner', custommodel, config=config,tokenizer=tokenizer,aggregation_strategy='simple')\n",
    "#customNER(sequence)\n",
    "customNER(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "label_list = [\n",
    "    \"O\",       # Outside of a named entity\n",
    "    \"B-MISC\",  # Beginning of a miscellaneous entity right after another miscellaneous entity\n",
    "    \"I-MISC\",  # Miscellaneous entity\n",
    "    \"B-PER\",   # Beginning of a person's name right after another person's name\n",
    "    \"I-PER\",   # Person's name\n",
    "    \"B-ORG\",   # Beginning of an organisation right after another organisation\n",
    "    \"I-ORG\",   # Organisation\n",
    "    \"B-LOC\",   # Beginning of a location right after another location\n",
    "    \"I-LOC\"    # Location\n",
    "]\n",
    "\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(inputs).logits\n",
    "predictions = torch.argmax(outputs, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

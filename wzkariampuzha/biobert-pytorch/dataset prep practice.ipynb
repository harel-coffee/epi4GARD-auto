{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602623f5",
   "metadata": {},
   "source": [
    "First need to see the form of the datasets that are prepared. There are four types:\n",
    "- devel.tsv\n",
    "- test.tsv\n",
    "- train.tsv\n",
    "- train_dev.tsv\n",
    "Will only be training on the NCBI Disease, 2010 i2b2/VA, BC5DR disease sets + my own records and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2529b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2684d488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 47788: unexpected end of data\n",
      "Skipping line 47814: field larger than field limit (131072)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46039 124676 94817 117390\n"
     ]
    }
   ],
   "source": [
    "#See what the .tsv file looks like, can remove later\n",
    "#train_dev = \"./datasets/NER/NCBI-disease/train_dev.tsv\"\n",
    "train = \"./datasets/NER/BC5CDR-disease/train.tsv\" \n",
    "test = \"./datasets/NER/BC5CDR-disease/test.tsv\"\n",
    "train_dev = \"./datasets/NER/BC5CDR-disease/train_dev.tsv\"\n",
    "devel = \"./datasets/NER/BC5CDR-disease/devel.tsv\"\n",
    "\n",
    "#Used this to find out if they used 80:20 split for training/validation - they did not\n",
    "train_df = pd.read_csv(train, sep='\\t',engine='python',error_bad_lines=False, names= [\"Word\",\"Label\"])\n",
    "test_df = pd.read_csv(test, sep='\\t', names= [\"Word\",\"Label\"])\n",
    "train_dev_df = pd.read_csv(train_dev, sep='\\t',engine='python',error_bad_lines=False)\n",
    "devel_df = pd.read_csv(devel, sep='\\t')\n",
    "print(len(train_df.index), len(test_df.index), len(train_dev_df.index), len(devel_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b59dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torsade</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pointes</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ventricular</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tachycardia</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124671</th>\n",
       "      <td>monitored</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124672</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124673</th>\n",
       "      <td>gingival</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124674</th>\n",
       "      <td>hyperplasia</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124675</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word Label\n",
       "0           Torsade     B\n",
       "1                de     I\n",
       "2           pointes     I\n",
       "3       ventricular     B\n",
       "4       tachycardia     I\n",
       "...             ...   ...\n",
       "124671    monitored     O\n",
       "124672          for     O\n",
       "124673     gingival     B\n",
       "124674  hyperplasia     I\n",
       "124675            .     O\n",
       "\n",
       "[124676 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdcfea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Selegiline</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>induced</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>postural</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hypotension</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46034</th>\n",
       "      <td>\\tO\\npulmonary\\tB\\nedema\\tI\\n,\\tO\\npreceded\\tO...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46035</th>\n",
       "      <td>Polfa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46036</th>\n",
       "      <td>\\tO\\n)\\tO\\nat\\tO\\nthe\\tO\\neffective\\tO\\ndose\\t...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46037</th>\n",
       "      <td>valproate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46038</th>\n",
       "      <td>encephalopathy</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46039 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Word Label\n",
       "0                                             Selegiline     O\n",
       "1                                                      -     O\n",
       "2                                                induced     O\n",
       "3                                               postural     B\n",
       "4                                            hypotension     I\n",
       "...                                                  ...   ...\n",
       "46034  \\tO\\npulmonary\\tB\\nedema\\tI\\n,\\tO\\npreceded\\tO...     O\n",
       "46035                                              Polfa     O\n",
       "46036  \\tO\\n)\\tO\\nat\\tO\\nthe\\tO\\neffective\\tO\\ndose\\t...     O\n",
       "46037                                          valproate     O\n",
       "46038                                     encephalopathy     B\n",
       "\n",
       "[46039 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823cb143",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conllpp (/work/wzkariampuzha/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "coNLL = load_dataset(\"conllpp\")\n",
    "coNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a748ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coNLL[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f259e671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BRUSSELS', 'B'),\n",
       " ('1996-08-22', 'O'),\n",
       " ('Germany', 'B'),\n",
       " (\"'s\", 'O'),\n",
       " ('representative', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('European', 'O'),\n",
       " ('Union', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('veterinary', 'O'),\n",
       " ('committee', 'O'),\n",
       " ('Werner', 'O'),\n",
       " ('Zwingmann', 'O'),\n",
       " ('said', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Wednesday', 'O'),\n",
       " ('consumers', 'O'),\n",
       " ('should', 'O'),\n",
       " ('buy', 'O'),\n",
       " ('sheepmeat', 'O'),\n",
       " ('from', 'O'),\n",
       " ('countries', 'O'),\n",
       " ('other', 'O'),\n",
       " ('than', 'O')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NER_tag '5' is B-LOC, '6' is I-LOC\n",
    "loc_data = []\n",
    "for sentence in coNLL[\"train\"]:\n",
    "    #Only add sentences that actually have location tags (i.e. meaningfully annotated sentences)\n",
    "    if (5 in sentence['ner_tags'] or 6 in sentence['ner_tags']):\n",
    "        i = 0\n",
    "        for tag in sentence['ner_tags']:\n",
    "            label = 'O'\n",
    "            if tag ==5:\n",
    "                label = 'B'\n",
    "            if tag == 6:\n",
    "                label = 'I'\n",
    "            entry = (sentence['tokens'][i], label) #Adding this as a tuple\n",
    "            loc_data.append(entry)\n",
    "            i+=1\n",
    "loc_data[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d4c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_labels(loc_data, label_file):\n",
    "    with open(label_file, 'w', encoding='utf8', newline='') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter='\\t', lineterminator='\\n')\n",
    "        #tsv_writer.writerow([\"Word\", \"Count\"])\n",
    "        for word, label in loc_data:\n",
    "            tsv_writer.writerow([word, label])\n",
    "#From https://stackoverflow.com/questions/29895602/how-to-save-output-from-python-like-tsv\n",
    "#Where word_count is a list of tuples like this:\n",
    "#[('the', 222594), ('to', 61479), ('in', 52540), ('of', 48064) ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a427de67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_file = \"./datasets/NER/labels.tsv\"\n",
    "save_labels(loc_data, label_file)\n",
    "#There might be an easier way to do this by not creating a file but I don't care to find one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "164c26ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(label_file, sep='\\t', names= [\"Word\",\"Label\"]) \n",
    "df.tail()\n",
    "import os\n",
    "os.remove(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dbdf5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.8\n",
    "half = int(len(df.index)/2)\n",
    "butterknife = int(train_test_split*(len(df.index)/2))\n",
    "\n",
    "df_1 = df[:half]\n",
    "df_2 = df[half:]\n",
    "\n",
    "train_df = df_1[:butterknife]\n",
    "test_df = df_1[butterknife:]\n",
    "train_dev_df = df_2[:butterknife]\n",
    "devel_df = df_2[butterknife:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f93376d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33746 8437 33746 8437\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df.index), len(test_df.index), len(train_dev_df.index), len(devel_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760e37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save files\n",
    "train = \"./datasets/NER/Location/train.tsv\" \n",
    "test = \"./datasets/NER/Location/test.tsv\"\n",
    "train_dev = \"./datasets/NER/Location/train_dev.tsv\"\n",
    "devel = \"./datasets/NER/Location/devel.tsv\"\n",
    "\n",
    "train_df.to_csv(train,sep='\\t',header=False, index = False)\n",
    "test_df.to_csv(test,sep='\\t',header=False, index = False)\n",
    "train_dev_df.to_csv(train_dev,sep='\\t',header=False, index = False)\n",
    "devel_df.to_csv(devel,sep='\\t',header=False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95872aec",
   "metadata": {},
   "source": [
    "This is using the train_test_split module, did not use it because BERT trains contextually so randomizing the words are most likely worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371ccd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x, y = train_test_split(df, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d512853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e11d01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce77fb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.groupby('Label').size().reset_index(name='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e6eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop('Label', axis=1)\n",
    "#print(X.to_dict('records')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1a341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.feature_extraction import DictVectorizer\\n\\nX = df.drop('Label', axis=1)\\nv = DictVectorizer(sparse=False)\\nX = v.fit_transform(X.to_dict('records'))\\ny = df.Label.values\\nclasses = np.unique(y)\\nclasses = classes.tolist()\\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=0)\\nX_train.shape, y_train.shape\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X = df.drop('Label', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "y = df.Label.values\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=0)\n",
    "X_train.shape, y_train.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d186b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d00de536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import Perceptron\n",
    "#per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "#per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a6b858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_classes = classes.copy()\n",
    "#new_classes.pop()\n",
    "#new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5b1d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
